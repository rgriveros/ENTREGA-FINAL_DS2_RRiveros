{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPS4L3HsQt965nWDswFcef4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rgriveros/ENTREGA-FINAL_DS2_RRiveros/blob/main/EntregaFinal_DS2_RRiveros.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EntregaFinal — Proyectos Mineros en Argentina**\n",
        "## Autor: **Gabriel Riveros Lobos**  \n",
        "## Fecha: 13/11/2025  \n",
        "## Objetivo del notebook: **Predecir si un proyecto minero alcanza etapa avanzada (clasificación binaria).**  \n",
        "## Métrica principal: AUC (Area Under ROC).  \n",
        "\n",
        "## **Contexto:**\n",
        "Cartera de proyectos mineros con atributos técnicos, geográficos y de propiedad. Los equipos de evaluación y toma de decisiones necesitan priorizar recursos y planificar inversiones.\n",
        "\n",
        "## **Objetivo:**\n",
        "Construir un modelo de clasificación para predecir si un proyecto alcanzará una etapa avanzada (sí/no), facilitando priorización de inversión y asignación de recursos operativos.\n",
        "Pregunta de negocio: ¿Qué proyectos de la cartera tienen alta probabilidad de alcanzar una etapa avanzada y, por tanto, merecen priorización de inversión?\n",
        "\n",
        "## **Audiencia beneficiada:**\n",
        "Gerencias de proyectos, analistas de cartera e inversores que requieren señales tempranas sobre proyectos con mayor probabilidad de avance.\n",
        "\n",
        "## **Métrica principal:**\n",
        "AUC ROC — elegida por su robustez ante desequilibrios en clases y porque mide la capacidad global del modelo para distinguir proyectos que avanzan de los que no.\n",
        "\n",
        "### Justificación corta de la métrica\n",
        "AUC ROC está indicada porque: Maneja bien clases desbalanceadas sin requerir un umbral fijo. Permite comparar modelos independientemente del coste asociado a falsos positivos/negativos; luego se puede fijar umbral según trade-off operativo.\n",
        "\n",
        "## **Resumen ejecutivo:**\n",
        "Este notebook presenta la carga y limpieza de datos, la ingeniería de features, la comparación de modelos (baseline vs tree-based), la optimización ligera de hiperparámetros y la explicación del modelo final con SHAP. El entregable incluye el modelo final serializado, métricas comparativas y recomendaciones operativas para priorizar la cartera.\n",
        "\n",
        "\n",
        "---\n",
        "## **Instrucciones rápidas:**  \n",
        "Clonar el repo.\n",
        "pip install -r requirements.txt..\n",
        "Ejecutar la celda \"2 — Preparación\" del notebook (descarga automática vía CKAN y guarda data/dataset.csv).\n"
      ],
      "metadata": {
        "id": "Gb-a7bzFMUBc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Requisitos, entorno y reproducibilidad\n",
        "\n",
        "Objetivo: dejar configurado el entorno mínimo necesario para que el notebook sea reproducible y ejecutable en Colab y en cualquier máquina local con Python. Esto incluye:\n",
        "- Declarar y fijar la semilla global (RANDOM_STATE).\n",
        "- Importar librerías clave y mostrar versiones para trazabilidad.\n",
        "- Definir y crear la estructura de carpetas usada por el proyecto.\n",
        "- Generar archivos iniciales: `README_colab.txt` y `data/sample_input.csv` (muestra vacía), listos para subir al repo.\n",
        "\n"
      ],
      "metadata": {
        "id": "hK1dh2ssejCr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.2 Imports, seed, paths y creación de estructura\n",
        "import sys, os, platform\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib, matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "import joblib\n",
        "from datetime import datetime\n",
        "\n",
        "# Semilla reproducible\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "\n",
        "# Imprimir versiones clave para reproducibilidad\n",
        "print(\"Python:\", sys.version.splitlines()[0])\n",
        "print(\"Platform:\", platform.platform())\n",
        "print(\"NumPy:\", np.__version__)\n",
        "print(\"Pandas:\", pd.__version__)\n",
        "print(\"Matplotlib:\", matplotlib.__version__)\n",
        "print(\"Seaborn:\", sns.__version__)\n",
        "print(\"Scikit-learn:\", sklearn.__version__)\n",
        "print(\"Joblib:\", joblib.__version__)\n",
        "print(\"RANDOM_STATE set to\", RANDOM_STATE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rC7tq5LSevU2",
        "outputId": "7ce00004-b2b2-4a75-f55b-95ed1fa59192"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
            "Platform: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "NumPy: 2.0.2\n",
            "Pandas: 2.2.2\n",
            "Matplotlib: 3.10.0\n",
            "Seaborn: 0.13.2\n",
            "Scikit-learn: 1.6.1\n",
            "Joblib: 1.5.2\n",
            "RANDOM_STATE set to 42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carga de Datos y chequeo rápido EDA\n",
        "\n",
        "Objetivo:\n",
        "\n",
        "Esta celda descarga el dataset público desde la API CKAN de datos.gob.ar (package_search → package_show → recurso CSV/XLSX), guarda el archivo en la carpeta local data/ del repositorio y genera un snapshot local para trazabilidad. No requiere acceso a Google Drive. Variables editables: QUERY, ROWS, VERIFY_SSL. Mantener VERIFY_SSL = True; usar False solo si el entorno falla por certificado (documentar el uso). Dependencias: requests, pandas, openpyxl (si hay Excel).\n"
      ],
      "metadata": {
        "id": "Xgjtjt-DRa6C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Descarga por API CKAN -> guarda en ./data/ -> lee y snapshot\n",
        "import requests\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# ---------- EDITAR SOLO ESTAS VARIABLES ----------\n",
        "CKAN_BASE = \"https://datos.gob.ar/api/3/action\"\n",
        "QUERY = \"Proyectos mineros metalíferos y de litio\"\n",
        "ROWS = 5\n",
        "VERIFY_SSL = False   # True recomendado; False solo si hay error certificado y lo documentás\n",
        "# -------------------------------------------------\n",
        "\n",
        "DATA_DIR = Path(\"data\")\n",
        "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def ck_search_and_download(query, rows=5, verify_ssl=True, retries=2, backoff=2):\n",
        "    for attempt in range(retries + 1):\n",
        "        try:\n",
        "            r = requests.get(f\"{CKAN_BASE}/package_search\", params={\"q\": query, \"rows\": rows}, timeout=30, verify=verify_ssl)\n",
        "            r.raise_for_status()\n",
        "            results = r.json().get(\"result\", {}).get(\"results\", [])\n",
        "            if not results:\n",
        "                raise FileNotFoundError(f\"No se encontraron paquetes para la query: '{query}'\")\n",
        "            first = results[0]\n",
        "            pkg_id = first.get(\"id\") or first.get(\"name\")\n",
        "            r2 = requests.get(f\"{CKAN_BASE}/package_show\", params={\"id\": pkg_id}, timeout=30, verify=verify_ssl)\n",
        "            r2.raise_for_status()\n",
        "            pkg = r2.json().get(\"result\", {})\n",
        "            resources = pkg.get(\"resources\", []) or []\n",
        "            for res in resources:\n",
        "                url = (res.get(\"url\") or \"\").strip()\n",
        "                if url.lower().endswith((\".csv\", \".xlsx\", \".xls\")):\n",
        "                    return pkg, url\n",
        "            raise FileNotFoundError(\"No se encontró recurso CSV/XLSX en el paquete seleccionado.\")\n",
        "        except (requests.RequestException, ValueError) as e:\n",
        "            if attempt < retries:\n",
        "                time.sleep(backoff * (attempt + 1))\n",
        "                continue\n",
        "            raise RuntimeError(f\"Fallo al consultar CKAN: {e}\")\n",
        "\n",
        "pkg_meta, res_url = ck_search_and_download(QUERY, ROWS, VERIFY_SSL)\n",
        "\n",
        "dst = DATA_DIR / (\"dataset_minero.csv\" if res_url.lower().endswith(\".csv\") else \"dataset_minero.xlsx\")\n",
        "with requests.get(res_url, stream=True, timeout=120, verify=VERIFY_SSL) as resp:\n",
        "    resp.raise_for_status()\n",
        "    with open(dst, \"wb\") as f:\n",
        "        for chunk in resp.iter_content(8192):\n",
        "            if chunk:\n",
        "                f.write(chunk)\n",
        "\n",
        "if dst.suffix.lower() == \".csv\":\n",
        "    df = pd.read_csv(dst, low_memory=False, encoding=\"utf-8\")\n",
        "else:\n",
        "    df = pd.read_excel(dst, engine=\"openpyxl\")\n",
        "\n",
        "# Guardar snapshot para trazabilidad\n",
        "snapshot = DATA_DIR / \"data_snapshot_head.csv\"\n",
        "df.head(200).to_csv(snapshot, index=False)\n",
        "\n",
        "# Salida mínima y reproducible\n",
        "print(\"Package:\", pkg_meta.get(\"title\") or pkg_meta.get(\"name\"))\n",
        "print(\"Fuente (URL):\", res_url)\n",
        "print(\"Guardado en:\", dst)\n",
        "print(\"Filas:\", df.shape[0], \"| Columnas:\", df.shape[1])\n",
        "print(df.isna().sum().sort_values(ascending=False).head(20).to_string())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6TBvK35A2lC",
        "outputId": "5800726c-bea3-476f-93d4-d9145a6a49e0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'datos.gob.ar'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'datos.gob.ar'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.mecon.gob.ar'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.economia.gob.ar'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Package: Cartera de Proyectos Mineros en Argentina del SIACAM\n",
            "Fuente (URL): https://www.mecon.gob.ar/dataset/Cartera-de-Proyectos-Mineros-Metaliferos-y-Litio-del-SIACAM.xlsx\n",
            "Guardado en: data/dataset_minero.xlsx\n",
            "Filas: 325 | Columnas: 17\n",
            "Unnamed: 16          324\n",
            "PORCENTAJE (3°)      235\n",
            "ORIGEN (2°)          233\n",
            "ORIGEN (3°)          232\n",
            "CONTROLANTE (3°)     232\n",
            "CONTROLANTE (2°)     231\n",
            "PORCENTAJE (2°)      229\n",
            "PORCENTAJE (1°)      122\n",
            "ORIGEN (1°)          121\n",
            "CONTROLANTE (1°)      97\n",
            "N°                     0\n",
            "PROVINCIA              0\n",
            "ESTADO                 0\n",
            "LATITUD                0\n",
            "NOMBRE                 0\n",
            "LONGITUD               0\n",
            "MINERAL PRINCIPAL      0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Guardando metadatos del paquete (id, title, url, fecha de descarga) para trazabilidad reproducible"
      ],
      "metadata": {
        "id": "Nx2b1ltSD-e9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar metadatos del paquete\n",
        "import json\n",
        "from datetime import datetime, timezone\n",
        "from pathlib import Path\n",
        "\n",
        "META_PATH = Path(\"data\")\n",
        "META_PATH.mkdir(parents=True, exist_ok=True)\n",
        "OUT = META_PATH / \"dataset_metadata.json\"\n",
        "\n",
        "def safe_str(x):\n",
        "    try:\n",
        "        return str(x)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "meta = {\n",
        "    \"package_id\": safe_str(pkg_meta.get(\"id\") if isinstance(pkg_meta, dict) else pkg_meta),\n",
        "    \"package_title\": safe_str(pkg_meta.get(\"title\") if isinstance(pkg_meta, dict) else pkg_meta),\n",
        "    \"resource_url\": safe_str(res_url),\n",
        "    \"downloaded_at\": datetime.now(timezone.utc).isoformat()\n",
        "}\n",
        "\n",
        "try:\n",
        "    with open(OUT, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(meta, f, ensure_ascii=False, indent=2)\n",
        "    print(\"Metadatos guardados en:\", OUT)\n",
        "except Exception as e:\n",
        "    print(\"Error al guardar metadatos:\", type(e).__name__, \"-\", e)\n",
        "    print(\"Contenido meta (fallback):\", {k: v for k, v in meta.items()})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLJWgf6uDsEf",
        "outputId": "6489c2c6-aea3-4487-d275-74280f44f1ed"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metadatos guardados en: data/dataset_metadata.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.dtypes)\n",
        "print(df.head(5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ks5oEBaXEFIe",
        "outputId": "5c37232f-86b8-4609-de7f-501391d0c984"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N°                     int64\n",
            "NOMBRE                object\n",
            "LATITUD              float64\n",
            "LONGITUD             float64\n",
            "MINERAL PRINCIPAL     object\n",
            "PROVINCIA             object\n",
            "ESTADO                object\n",
            "CONTROLANTE (1°)      object\n",
            "PORCENTAJE (1°)      float64\n",
            "ORIGEN (1°)           object\n",
            "CONTROLANTE (2°)      object\n",
            "ORIGEN (2°)           object\n",
            "PORCENTAJE (2°)       object\n",
            "CONTROLANTE (3°)      object\n",
            "PORCENTAJE (3°)       object\n",
            "ORIGEN (3°)           object\n",
            "Unnamed: 16           object\n",
            "dtype: object\n",
            "   N°             NOMBRE  LATITUD  LONGITUD MINERAL PRINCIPAL  PROVINCIA  \\\n",
            "0   1  20 de septiembre   -24.896   -68.136            Hierro      Salta   \n",
            "1   2           Acazoque  -24.291   -66.378             Plomo      Salta   \n",
            "2   3   Acoite/Hornillos  -22.305   -65.107             Plomo      Salta   \n",
            "3   4              Adamo  -41.162   -68.505               Oro  Río Negro   \n",
            "4   5      Aguas Amargas  -24.685   -66.903             Cobre      Salta   \n",
            "\n",
            "                ESTADO        CONTROLANTE (1°)  PORCENTAJE (1°) ORIGEN (1°)  \\\n",
            "0  Exploración inicial        Diego Ruben Omar              NaN         NaN   \n",
            "1  Exploración inicial             Nuñez Ramon              NaN         NaN   \n",
            "2  Exploración inicial  Rubiolo Daniel Gerardo              NaN         NaN   \n",
            "3          Prospección  Valcheta Exploraciones              1.0   Argentina   \n",
            "4  Exploración inicial     Lithium S Corp. S.A              NaN         NaN   \n",
            "\n",
            "  CONTROLANTE (2°) ORIGEN (2°) PORCENTAJE (2°) CONTROLANTE (3°)  \\\n",
            "0              NaN         NaN             NaN              NaN   \n",
            "1              NaN         NaN             NaN              NaN   \n",
            "2              NaN         NaN             NaN              NaN   \n",
            "3              NaN         NaN             NaN              NaN   \n",
            "4              NaN         NaN             NaN              NaN   \n",
            "\n",
            "  PORCENTAJE (3°) ORIGEN (3°) Unnamed: 16  \n",
            "0             NaN         NaN         NaN  \n",
            "1             NaN         NaN         NaN  \n",
            "2             NaN         NaN         NaN  \n",
            "3             NaN         NaN         NaN  \n",
            "4             NaN         NaN         NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Observación rápida sobre la salida\n",
        "La lectura funcionó, pero hay columnas que deberían ser numéricas (p. ej. las columnas PORCENTAJE (...)) y aparecen como object — eso suele pasar por valores mezclados (cadenas, comas decimales, símbolos % o celdas vacías/extrañas).\n",
        "\n",
        "Hay una columna Unnamed: 16 vacía en su mayoría — probable columna residual del Excel que conviene eliminar.\n",
        "\n",
        "Latitud/Longitud ya son float64 (bien).\n",
        "\n",
        "Antes de cualquier análisis sería conveniente:\n",
        "1) inspeccionar las celdas “problemáticas”,\n",
        "2) normalizar formatos numéricos,\n",
        "3) convertir a tipos correctos\n",
        "4) registrar los cambios (snapshot + metadata)."
      ],
      "metadata": {
        "id": "Nc6JhJ3vGK4F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Ingeniería de features y preprocesado reproducible"
      ],
      "metadata": {
        "id": "8tcdhb0UGx-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sección 4: Limpieza no destructiva -> guarda clean CSV, snapshot y metadata ampliada\n",
        "import re, json, time\n",
        "from pathlib import Path\n",
        "from datetime import datetime, timezone\n",
        "import pandas as pd\n",
        "\n",
        "# ----- Ajustar si fuera necesario -----\n",
        "DATA_DIR = Path(\"data\")\n",
        "RAW_FN = DATA_DIR / \"dataset_minero.xlsx\"   # cambiar si el raw tiene otro nombre\n",
        "OUT_CSV = DATA_DIR / \"dataset_minero_clean.csv\"\n",
        "SNAPSHOT_CSV = DATA_DIR / \"data_snapshot_head_clean.csv\"\n",
        "META_F = DATA_DIR / \"dataset_metadata.json\"\n",
        "# -------------------------------------\n",
        "\n",
        "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 0) cargar (si df ya existe en memoria, lo reutiliza)\n",
        "if 'df' not in globals():\n",
        "    if RAW_FN.exists():\n",
        "        if RAW_FN.suffix.lower() == \".csv\":\n",
        "            df = pd.read_csv(RAW_FN, low_memory=False, encoding=\"utf-8\")\n",
        "        else:\n",
        "            df = pd.read_excel(RAW_FN, engine=\"openpyxl\")\n",
        "    else:\n",
        "        raise FileNotFoundError(f\"Archivo raw no encontrado: {RAW_FN}\")"
      ],
      "metadata": {
        "id": "wNcNJJgKG7mK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# 1) detectar columnas objetivo\n",
        "pct_cols = [c for c in df.columns if \"PORCENTAJE\" in str(c).upper()]\n",
        "obj_cols = [c for c in df.columns if df[c].dtype == \"object\" and c not in pct_cols]\n",
        "\n",
        "print(\"Columnas detectadas como PORCENTAJE:\", pct_cols)\n",
        "print(\"Ejemplo de columnas object detectadas:\", obj_cols[:8])\n",
        "\n",
        "# 2) limpieza helper (devuelve float o None)\n",
        "def clean_numeric_value(x):\n",
        "    if pd.isna(x):\n",
        "        return None\n",
        "    s = str(x).strip()\n",
        "    if s == \"\" or s in (\"-\", \"--\"):\n",
        "        return None\n",
        "    s = s.replace(\"\\xa0\", \"\").replace(\" \", \"\")\n",
        "    # quitar texto no numérico salvo signos, decimales, exp y %\n",
        "    s = re.sub(r\"[^\\d\\-,.\\+eE%]\", \"\", s)\n",
        "    if s == \"\" or s in (\"-\", \"--\"):\n",
        "        return None\n",
        "    is_pct = s.endswith(\"%\")\n",
        "    if is_pct:\n",
        "        s = s[:-1]\n",
        "    # manejar '.' y ',' coexistentes\n",
        "    if \",\" in s and \".\" in s:\n",
        "        if s.rfind(\",\") > s.rfind(\".\"):\n",
        "            s = s.replace(\".\", \"\").replace(\",\", \".\")\n",
        "        else:\n",
        "            s = s.replace(\",\", \"\")\n",
        "    else:\n",
        "        if \",\" in s and \".\" not in s:\n",
        "            s = s.replace(\",\", \".\")\n",
        "    try:\n",
        "        v = float(s)\n",
        "        # si era %, normalizar a 0-1; si nombre de columna indica porcentaje y v>1 asumimos 0-100->0-1\n",
        "        return v/100.0 if is_pct else v\n",
        "    except Exception:\n",
        "        return None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBT-zBcpG2g-",
        "outputId": "5437508f-4c31-4c35-862e-9045cc2791f1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columnas detectadas como PORCENTAJE: ['PORCENTAJE (1°)', 'PORCENTAJE (2°)', 'PORCENTAJE (3°)']\n",
            "Ejemplo de columnas object detectadas: ['NOMBRE', 'MINERAL PRINCIPAL', 'PROVINCIA', 'ESTADO', 'CONTROLANTE (1°)', 'ORIGEN (1°)', 'CONTROLANTE (2°)', 'ORIGEN (2°)']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) aplicar a columnas PORCENTAJE y crear columnas *_clean (no sobreescribir)\n",
        "conversion_report = {}\n",
        "for c in pct_cols:\n",
        "    before = int(df[c].notna().sum())\n",
        "    cleaned = df[c].map(clean_numeric_value)\n",
        "    after = int(cleaned.notna().sum())\n",
        "    df[c + \"_clean\"] = cleaned\n",
        "    conversion_report[c] = {\"before_nonnull\": before, \"after_numeric\": after}\n",
        "\n",
        "# 4) opcional: aplicar a otras columnas object que el usuario confirme (aquí no se aplica por defecto)\n",
        "# Si querés convertir columnas adicionales, agrégalas a cols_to_convert\n",
        "cols_to_convert = []  # p. ej. [\"PORCENTAJE (2°)\"] si no fue detectada por nombre\n",
        "for c in cols_to_convert:\n",
        "    if c in df.columns:\n",
        "        before = int(df[c].notna().sum())\n",
        "        cleaned = df[c].map(clean_numeric_value)\n",
        "        after = int(cleaned.notna().sum())\n",
        "        df[c + \"_clean\"] = cleaned\n",
        "        conversion_report[c] = {\"before_nonnull\": before, \"after_numeric\": after}\n",
        "\n",
        "# 5) eliminar columnas vacías tipo Unnamed si están totalmente vacías\n",
        "unnamed = [c for c in df.columns if str(c).lower().startswith(\"unnamed\") and df[c].dropna().eq(\"\").all()]\n",
        "# además columnas con todos NaN\n",
        "allnan = [c for c in df.columns if df[c].isna().all()]\n",
        "drop_candidates = sorted(set(unnamed + allnan))\n",
        "if drop_candidates:\n",
        "    print(\"Columnas vacías a dropear (no destructivo todavía):\", drop_candidates)\n",
        "    df = df.drop(columns=drop_candidates, errors='ignore')"
      ],
      "metadata": {
        "id": "Qrfjm8r8HDuW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6) guardar clean CSV y snapshot head\n",
        "df.to_csv(OUT_CSV, index=False, encoding=\"utf-8\")\n",
        "df.head(200).to_csv(SNAPSHOT_CSV, index=False, encoding=\"utf-8\")\n",
        "\n",
        "# 7) metadata ampliada\n",
        "meta = {\n",
        "    \"package_title\": pkg_meta.get(\"title\") if 'pkg_meta' in globals() else None,\n",
        "    \"package_id\": pkg_meta.get(\"id\") if 'pkg_meta' in globals() else None,\n",
        "    \"resource_url\": res_url if 'res_url' in globals() else None,\n",
        "    \"raw_file\": str(RAW_FN),\n",
        "    \"clean_file\": str(OUT_CSV),\n",
        "    \"snapshot_file\": str(SNAPSHOT_CSV),\n",
        "    \"generated_at\": datetime.now(timezone.utc).isoformat().replace(\"+00:00\",\"Z\"),\n",
        "    \"conversion_report\": conversion_report,\n",
        "    \"dropped_columns\": drop_candidates\n",
        "}\n",
        "with open(META_F, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(meta, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"Limpieza aplicada (no destructiva). Archivos creados:\")\n",
        "print(\" - Clean dataset:\", OUT_CSV)\n",
        "print(\" - Snapshot head:\", SNAPSHOT_CSV)\n",
        "print(\" - Metadata:\", META_F)\n",
        "print(\"\\nResumen conversion_report (porcentaje columnas):\")\n",
        "print(json.dumps(conversion_report, indent=2, ensure_ascii=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93c7kWFwHHIn",
        "outputId": "86c36406-6486-4c6a-a7b7-54eced4c9e20"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Limpieza aplicada (no destructiva). Archivos creados:\n",
            " - Clean dataset: data/dataset_minero_clean.csv\n",
            " - Snapshot head: data/data_snapshot_head_clean.csv\n",
            " - Metadata: data/dataset_metadata.json\n",
            "\n",
            "Resumen conversion_report (porcentaje columnas):\n",
            "{\n",
            "  \"PORCENTAJE (1°)\": {\n",
            "    \"before_nonnull\": 203,\n",
            "    \"after_numeric\": 203\n",
            "  },\n",
            "  \"PORCENTAJE (2°)\": {\n",
            "    \"before_nonnull\": 96,\n",
            "    \"after_numeric\": 30\n",
            "  },\n",
            "  \"PORCENTAJE (3°)\": {\n",
            "    \"before_nonnull\": 90,\n",
            "    \"after_numeric\": 4\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ¿Qué haremos y por qué?\n",
        "\n",
        "Crear un respaldo del dataset actual sin modificar (backup CSV) para preservar la fuente antes de cualquier cambio.\n",
        "\n",
        "Reemplazar cada columna original por su columna correspondiente con sufijo _clean (si existe) para aplicar la limpieza validada en la sección anterior. Mantendremos también las columnas _clean en el archivo final para trazabilidad.\n",
        "\n",
        "Guardar el dataset resultante como data/dataset_minero_clean_applied.csv y actualizar dataset_metadata.json con el registro de cambios (qué columnas se reemplazaron, conteos antes/después, timestamp y ruta del backup).\n",
        "\n",
        "### Beneficios y trazabilidad\n",
        "\n",
        "Reversibilidad: el respaldo permite restaurar el estado previo si detectás problemas más adelante.\n",
        "\n",
        "Auditoría: metadata contiene package id/title, resource_url, columnas reemplazadas y contadores, lo que facilita reproducir y auditar exactamente lo que se cambió.\n",
        "\n",
        "Seguridad para el revisor: la limpieza ya fue aplicada solo después de la inspección en Sección 3; aquí se realiza la operación irreversible controlada y documentada."
      ],
      "metadata": {
        "id": "bhSTseq0Iv5t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sección 4.1 Renombrar *_clean -> sobrescribir columnas originales con backup\n",
        "import json\n",
        "from pathlib import Path\n",
        "from datetime import datetime, timezone\n",
        "import pandas as pd\n",
        "import shutil\n",
        "\n",
        "DATA_DIR = Path(\"data\")\n",
        "RAW_FN = DATA_DIR / \"dataset_minero.xlsx\"\n",
        "BACKUP_RAW_CSV = DATA_DIR / \"dataset_minero_raw_backup.csv\"\n",
        "OUT_APPLIED = DATA_DIR / \"dataset_minero_clean_applied.csv\"\n",
        "META_F = DATA_DIR / \"dataset_metadata.json\"\n",
        "\n",
        "# 4.1.0) cargar df (si no existe en memoria lo leemos del clean intermedio o del raw)\n",
        "if 'df' not in globals():\n",
        "    # preferimos el clean intermedio si existe\n",
        "    candidate_clean = DATA_DIR / \"dataset_minero_clean.csv\"\n",
        "    if candidate_clean.exists():\n",
        "        df = pd.read_csv(candidate_clean, low_memory=False, encoding=\"utf-8\")\n",
        "    elif RAW_FN.exists():\n",
        "        if RAW_FN.suffix.lower() == \".csv\":\n",
        "            df = pd.read_csv(RAW_FN, low_memory=False, encoding=\"utf-8\")\n",
        "        else:\n",
        "            df = pd.read_excel(RAW_FN, engine=\"openpyxl\")\n",
        "    else:\n",
        "        raise FileNotFoundError(\"No se encontró ningún dataset intermedio ni raw para aplicar los cambios.\")"
      ],
      "metadata": {
        "id": "ZLZUMC3IJGRc"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.1.1) identificar columnas *_clean y sus originales\n",
        "clean_cols = [c for c in df.columns if isinstance(c, str) and c.endswith(\"_clean\")]\n",
        "mapping = {}\n",
        "for c in clean_cols:\n",
        "    orig = c[:-6]  # quitar sufijo \"_clean\"\n",
        "    if orig in df.columns:\n",
        "        mapping[orig] = c\n",
        "\n",
        "if not mapping:\n",
        "    raise RuntimeError(\"No se encontraron columnas *_clean que correspondan a columnas originales. Nada que aplicar.\")\n",
        "\n",
        "print(\"Columnas a reemplazar (original -> *_clean):\")\n",
        "for orig, clean in mapping.items():\n",
        "    print(f\" - {orig}  <-  {clean}\")\n",
        "\n",
        "# 4.1.2) crear backup CSV del estado actual (antes de aplicar)\n",
        "df.to_csv(BACKUP_RAW_CSV, index=False, encoding=\"utf-8\")\n",
        "print(\"Backup creado en:\", BACKUP_RAW_CSV)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXTPfAlVJLjH",
        "outputId": "f27c8569-d4b2-4232-b924-1c632817ed71"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columnas a reemplazar (original -> *_clean):\n",
            " - PORCENTAJE (1°)  <-  PORCENTAJE (1°)_clean\n",
            " - PORCENTAJE (2°)  <-  PORCENTAJE (2°)_clean\n",
            " - PORCENTAJE (3°)  <-  PORCENTAJE (3°)_clean\n",
            "Backup creado en: data/dataset_minero_raw_backup.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.1.3) aplicar reemplazo: para cada mapping, mover valores de columna_clean a columna original\n",
        "replaced = {}\n",
        "for orig, clean in mapping.items():\n",
        "    before_nonnull = int(df[orig].notna().sum()) if orig in df.columns else 0\n",
        "    # asignar valores limpios sobre la columna original\n",
        "    df[orig] = df[clean]\n",
        "    after_nonnull = int(df[orig].notna().sum())\n",
        "    replaced[orig] = {\"clean_column\": clean, \"before_nonnull\": before_nonnull, \"after_nonnull\": after_nonnull}\n",
        "\n",
        "# 4.1.4) guardar dataset final aplicado\n",
        "df.to_csv(OUT_APPLIED, index=False, encoding=\"utf-8\")\n",
        "print(\"Dataset final guardado en:\", OUT_APPLIED)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzLWQ2ljJVOd",
        "outputId": "da49f736-4639-41e3-a7bd-f21dfe8439ae"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset final guardado en: data/dataset_minero_clean_applied.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.1.5) actualizar metadata (leer la previa si existe y extenderla)\n",
        "meta = {}\n",
        "if META_F.exists():\n",
        "    try:\n",
        "        with open(META_F, \"r\", encoding=\"utf-8\") as f:\n",
        "            meta = json.load(f)\n",
        "    except Exception:\n",
        "        meta = {}\n",
        "\n",
        "meta_update = {\n",
        "    \"applied_at\": datetime.now(timezone.utc).isoformat().replace(\"+00:00\",\"Z\"),\n",
        "    \"backup_raw_csv\": str(BACKUP_RAW_CSV),\n",
        "    \"applied_file\": str(OUT_APPLIED),\n",
        "    \"columns_replaced\": replaced\n",
        "}\n",
        "meta.update(meta_update)\n",
        "\n",
        "with open(META_F, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(meta, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"\\nMetadata actualizada en:\", META_F)\n",
        "print(\"Resumen cambios:\")\n",
        "import pprint\n",
        "pprint.pprint(replaced)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87u6FxOZJWVP",
        "outputId": "65622fb3-fa49-4261-dc7a-051aa7b8b5f3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Metadata actualizada en: data/dataset_metadata.json\n",
            "Resumen cambios:\n",
            "{'PORCENTAJE (1°)': {'after_nonnull': 203,\n",
            "                     'before_nonnull': 203,\n",
            "                     'clean_column': 'PORCENTAJE (1°)_clean'},\n",
            " 'PORCENTAJE (2°)': {'after_nonnull': 30,\n",
            "                     'before_nonnull': 96,\n",
            "                     'clean_column': 'PORCENTAJE (2°)_clean'},\n",
            " 'PORCENTAJE (3°)': {'after_nonnull': 4,\n",
            "                     'before_nonnull': 90,\n",
            "                     'clean_column': 'PORCENTAJE (3°)_clean'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Features y Preprocesado reproducible\n",
        "\n",
        "## Objetivo:\n",
        "definir y aplicar transformaciones necesarias de forma reproducible y versionable. Cómo usar: ejecutar la celda de definición de funciones y pipeline, luego pipeline, maps = build_preprocessing_pipeline() y df_transformed = apply_transformations(df, pipeline, maps).\n",
        "\n",
        "Transformaciones propuestas y justificación (priorizar variables de alto impacto):\n",
        "\n",
        "## LIMPIEZA:\n",
        "Eliminar columnas vacías y normalizar nombres de columna para evitar errores de parsing en producción.\n",
        "\n",
        "## CODIFICACIÓN ORDINAL de ESTADO → ESTADO_ORD:\n",
        "Mantiene orden implícito de avance (p. ej. Prospección < Exploración < Desarrollo < Producción) y ayuda a modelos lineales/árbol.\n",
        "\n",
        "## AGRUPACIÓN REGIONAL (PROVINCIA → REGION):\n",
        "reduce cardinalidad y captura correlaciones geográficas.\n",
        "\n",
        "## ENCODING MINERAL (MINERAL PRINCIPAL):\n",
        "target/one-hot según modelo; por defecto usamos OneHotEncoder limitado a top-k (resto -> Otros).\n",
        "\n",
        "## LAT/LONG:\n",
        "mantener como numérico y generar columnas de lat-long normalizadas (StandardScaler). Posible derivación: cluster geográfico (KMeans) opcional.\n",
        "\n",
        "## PORCENTAJES:\n",
        "usar columnas ya normalizadas (_clean) y rellenar NaN con 0 si semántica indica ausencia.\n",
        "\n",
        "## FEATURES DERIVADOS:\n",
        "Contar controlantes (si hay múltiples columnas CONTROLANTE n°) -> número de empresas asociadas; texto a bandera (presence/absence).\n",
        "\n",
        "## TIPOS Y CONSISTENCIA:\n",
        "Asegurar tipos numéricos para todas las columnas numéricas y strings para categóricas.\n",
        "\n",
        "## Checks mínimos:\n",
        "No pérdida de filas al aplicar pipeline.\n",
        "Tipos finales correctos.\n",
        "Reutilizabilidad: apply_transformations devuelve df y diccionarios de mapeo/encoders.\n",
        "\n",
        "Artefactos:\n",
        "pipeline.joblib (pipeline completo)\n",
        "encoders.joblib (mapas simples, p. ej. ESTADO map)\n",
        "pipeline_description.md (lista de transformaciones aplicadas y orden)"
      ],
      "metadata": {
        "id": "0LLd_x-6LG1s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helpers y mapeos"
      ],
      "metadata": {
        "id": "m9s3Ki3qUiBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.A Helpers y mapeos mínimos\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "def build_estado_map():\n",
        "    return {\"Prospección\":0,\"Exploración inicial\":1,\"Exploración avanzada\":2,\"Desarrollo\":3,\"Producción\":4}\n",
        "\n",
        "def province_to_region(s):\n",
        "    norte = {\"Salta\",\"Jujuy\",\"Catamarca\",\"Santiago del Estero\",\"Tucumán\",\"La Rioja\"}\n",
        "    centro = {\"Córdoba\",\"San Luis\",\"Santa Fe\",\"Entre Ríos\"}\n",
        "    sur = {\"Río Negro\",\"Neuquén\",\"Chubut\",\"Santa Cruz\",\"Tierra del Fuego\"}\n",
        "    s = pd.Series(s).astype(str).str.strip()\n",
        "    out = s.map(lambda p: \"Desconocido\" if p.lower() in (\"nan\",\"\") else (\"Norte\" if p in norte else \"Centro\" if p in centro else \"Sur\" if p in sur else \"Otra\"))\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "gxvgJce1TktF"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### builder del pipeline"
      ],
      "metadata": {
        "id": "iNNhgQ4MUnCA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.B Pipeline compacto: detecta columnas en df y construye ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "def build_compact_pipeline(df, topk_minerals=8):\n",
        "    numeric = [c for c in df.columns if c in (\"LATITUD\",\"LONGITUD\") or (\"PORCENTAJE\" in c.upper() and \"_clean\" in c)]\n",
        "    # fallback by dtype\n",
        "    if not numeric:\n",
        "        numeric = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]\n",
        "    # top-k minerals\n",
        "    top_m = df.get(\"MINERAL PRINCIPAL\", pd.Series()).fillna(\"Desconocido\").value_counts().index[:topk_minerals].tolist()\n",
        "    # pipelines\n",
        "    num_pipe = Pipeline([(\"imp\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())])\n",
        "    # FIX: Ensure 2D output for 'estado' transformer\n",
        "    estado_pipe = Pipeline([(\"map\", FunctionTransformer(lambda x: x.iloc[:, 0].astype(str).map(build_estado_map()).to_frame(), validate=False))])\n",
        "    # FIX: Ensure 2D output for 'region' transformer\n",
        "    region_pipe = Pipeline([(\"map\", FunctionTransformer(lambda x: province_to_region(x.iloc[:, 0]).to_frame(), validate=False))])\n",
        "    # FIX: Extract the single column from DataFrame 'x' before processing AND ensure 2D output for OneHotEncoder\n",
        "    mineral_pipe = Pipeline([(\"topk\", FunctionTransformer(lambda x: pd.Series(x.iloc[:, 0]).fillna(\"Desconocido\").astype(str).apply(lambda v: v if v in top_m else \"Otros\").to_frame(), validate=False)),\n",
        "                             (\"ohe\", OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\"))])\n",
        "    ct = ColumnTransformer([\n",
        "        (\"num\", num_pipe, numeric),\n",
        "        (\"estado\", estado_pipe, [\"ESTADO\"]),\n",
        "        (\"region\", region_pipe, [\"PROVINCIA\"]),\n",
        "        (\"mineral\", mineral_pipe, [\"MINERAL PRINCIPAL\"]),\n",
        "    ], remainder=\"passthrough\", verbose_feature_names_out=False)\n",
        "    return Pipeline([(\"preproc\", ct)]), {\"numeric\": numeric, \"top_minerals\": top_m}"
      ],
      "metadata": {
        "id": "cZIzJVY4ToIf"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### fit, transform, reconstrucción mínima y test"
      ],
      "metadata": {
        "id": "hWwQCKMUUuT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.C Fit + transform + reconstrucción mínima + test 3 filas\n",
        "from IPython.display import display\n",
        "import numpy as np, pandas as pd\n",
        "\n",
        "pipeline, maps = build_compact_pipeline(df, topk_minerals=8)\n",
        "fitted = pipeline.fit(df)                # fit sobre el dataset limpio\n",
        "arr = fitted.transform(df)\n",
        "\n",
        "# Reconstrucción mínima: numeric, estado, region, minerals, remainder\n",
        "n_num = len(maps[\"numeric\"])\n",
        "n_min = len(maps[\"top_minerals\"]) + 1   # +1 = \"Otros\" si aparece\n",
        "idx = 0\n",
        "parts = {}\n",
        "if n_num>0:\n",
        "    parts.update({f\"num_{c}\": arr[:, idx+i].astype(float) for i,c in enumerate(maps[\"numeric\"])})\n",
        "    idx += n_num\n",
        "parts[\"ESTADO_ORD\"] = arr[:, idx].astype(float); idx += 1\n",
        "parts[\"REGION\"] = pd.Series(arr[:, idx].astype(object)).replace({np.nan: None}); idx += 1\n",
        "min_cols = [f\"mineral_{m}\" for m in maps[\"top_minerals\"]] + [\"mineral_Otros\"]\n",
        "for i, name in enumerate(min_cols):\n",
        "    parts[name] = arr[:, idx + i].astype(int)\n",
        "idx += n_min\n",
        "# remainder (si existe)\n",
        "if arr.shape[1] > idx:\n",
        "    rem = arr[:, idx:]\n",
        "    # assign generic names for remainder; keep original df columns not used above\n",
        "    used = set(maps[\"numeric\"] + [\"ESTADO\",\"PROVINCIA\",\"MINERAL PRINCIPAL\"])\n",
        "    rem_names = [c for c in df.columns if c not in used]\n",
        "    if rem.shape[1] != len(rem_names):\n",
        "        rem_names = [f\"remainder_{i}\" for i in range(rem.shape[1])]\n",
        "    for i, name in enumerate(rem_names):\n",
        "        parts[name] = rem[:, i]\n",
        "\n",
        "df_trans = pd.DataFrame(parts, index=df.index)\n",
        "# Tests rápidos\n",
        "display(pd.concat([df.head(3).reset_index(drop=True), df_trans.head(3).reset_index(drop=True)], axis=1))\n",
        "print(\"Filas originales:\", len(df), \"| Filas transformadas:\", len(df_trans))\n",
        "print(\"Tipos transformado (ejemplo):\")\n",
        "print(df_trans.dtypes.apply(lambda x: x.name).to_string())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 800
        },
        "id": "gRhFwdb2TsWS",
        "outputId": "e0705822-aca9-4dd9-d2bf-3ae587f9f8b6"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   N°             NOMBRE  LATITUD  LONGITUD MINERAL PRINCIPAL PROVINCIA  \\\n",
              "0   1  20 de septiembre   -24.896   -68.136            Hierro     Salta   \n",
              "1   2           Acazoque  -24.291   -66.378             Plomo     Salta   \n",
              "2   3   Acoite/Hornillos  -22.305   -65.107             Plomo     Salta   \n",
              "\n",
              "                ESTADO        CONTROLANTE (1°) PORCENTAJE (1°)  ORIGEN (1°)  \\\n",
              "0  Exploración inicial        Diego Ruben Omar             NaN          NaN   \n",
              "1  Exploración inicial             Nuñez Ramon             NaN          NaN   \n",
              "2  Exploración inicial  Rubiolo Daniel Gerardo             NaN          NaN   \n",
              "\n",
              "   ...        CONTROLANTE (1°) PORCENTAJE (1°)  ORIGEN (1°) CONTROLANTE (2°)  \\\n",
              "0  ...        Diego Ruben Omar             NaN          NaN              NaN   \n",
              "1  ...             Nuñez Ramon             NaN          NaN              NaN   \n",
              "2  ...  Rubiolo Daniel Gerardo             NaN          NaN              NaN   \n",
              "\n",
              "   ORIGEN (2°) PORCENTAJE (2°) CONTROLANTE (3°)  PORCENTAJE (3°)  ORIGEN (3°)  \\\n",
              "0          NaN             NaN              NaN              NaN          NaN   \n",
              "1          NaN             NaN              NaN              NaN          NaN   \n",
              "2          NaN             NaN              NaN              NaN          NaN   \n",
              "\n",
              "   Unnamed: 16  \n",
              "0          NaN  \n",
              "1          NaN  \n",
              "2          NaN  \n",
              "\n",
              "[3 rows x 48 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8827edf8-400b-46bf-bfcd-970e34608826\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>N°</th>\n",
              "      <th>NOMBRE</th>\n",
              "      <th>LATITUD</th>\n",
              "      <th>LONGITUD</th>\n",
              "      <th>MINERAL PRINCIPAL</th>\n",
              "      <th>PROVINCIA</th>\n",
              "      <th>ESTADO</th>\n",
              "      <th>CONTROLANTE (1°)</th>\n",
              "      <th>PORCENTAJE (1°)</th>\n",
              "      <th>ORIGEN (1°)</th>\n",
              "      <th>...</th>\n",
              "      <th>CONTROLANTE (1°)</th>\n",
              "      <th>PORCENTAJE (1°)</th>\n",
              "      <th>ORIGEN (1°)</th>\n",
              "      <th>CONTROLANTE (2°)</th>\n",
              "      <th>ORIGEN (2°)</th>\n",
              "      <th>PORCENTAJE (2°)</th>\n",
              "      <th>CONTROLANTE (3°)</th>\n",
              "      <th>PORCENTAJE (3°)</th>\n",
              "      <th>ORIGEN (3°)</th>\n",
              "      <th>Unnamed: 16</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>20 de septiembre</td>\n",
              "      <td>-24.896</td>\n",
              "      <td>-68.136</td>\n",
              "      <td>Hierro</td>\n",
              "      <td>Salta</td>\n",
              "      <td>Exploración inicial</td>\n",
              "      <td>Diego Ruben Omar</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>Diego Ruben Omar</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Acazoque</td>\n",
              "      <td>-24.291</td>\n",
              "      <td>-66.378</td>\n",
              "      <td>Plomo</td>\n",
              "      <td>Salta</td>\n",
              "      <td>Exploración inicial</td>\n",
              "      <td>Nuñez Ramon</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>Nuñez Ramon</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Acoite/Hornillos</td>\n",
              "      <td>-22.305</td>\n",
              "      <td>-65.107</td>\n",
              "      <td>Plomo</td>\n",
              "      <td>Salta</td>\n",
              "      <td>Exploración inicial</td>\n",
              "      <td>Rubiolo Daniel Gerardo</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>Rubiolo Daniel Gerardo</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 48 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8827edf8-400b-46bf-bfcd-970e34608826')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8827edf8-400b-46bf-bfcd-970e34608826 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8827edf8-400b-46bf-bfcd-970e34608826');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b47b7c00-b5ae-4d23-9dfc-dc8253c49e61\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b47b7c00-b5ae-4d23-9dfc-dc8253c49e61')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b47b7c00-b5ae-4d23-9dfc-dc8253c49e61 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filas originales: 325 | Filas transformadas: 325\n",
            "Tipos transformado (ejemplo):\n",
            "num_LATITUD                  float64\n",
            "num_LONGITUD                 float64\n",
            "num_PORCENTAJE (1°)_clean    float64\n",
            "num_PORCENTAJE (2°)_clean    float64\n",
            "num_PORCENTAJE (3°)_clean    float64\n",
            "ESTADO_ORD                   float64\n",
            "REGION                        object\n",
            "mineral_Cobre                  int64\n",
            "mineral_Litio                  int64\n",
            "mineral_Oro                    int64\n",
            "mineral_Plata                  int64\n",
            "mineral_Plomo                  int64\n",
            "mineral_Uranio                 int64\n",
            "mineral_Hierro                 int64\n",
            "mineral_Manganeso              int64\n",
            "mineral_Otros                  int64\n",
            "N°                            object\n",
            "NOMBRE                        object\n",
            "CONTROLANTE (1°)              object\n",
            "PORCENTAJE (1°)               object\n",
            "ORIGEN (1°)                   object\n",
            "CONTROLANTE (2°)              object\n",
            "ORIGEN (2°)                   object\n",
            "PORCENTAJE (2°)               object\n",
            "CONTROLANTE (3°)              object\n",
            "PORCENTAJE (3°)               object\n",
            "ORIGEN (3°)                   object\n",
            "Unnamed: 16                   object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce3c3c5f",
        "outputId": "f5619389-9bda-403f-f176-8143dde68722"
      },
      "source": [
        "# 4.D Revisar y coercionar columnas 'object' restantes en df_trans\n",
        "\n",
        "print(\"--- Columnas con dtype 'object' en df_trans y muestra de valores ---\")\n",
        "\n",
        "object_cols_in_trans = df_trans.select_dtypes(include='object').columns\n",
        "\n",
        "if len(object_cols_in_trans) == 0:\n",
        "    print(\"¡No hay columnas con dtype 'object' en df_trans! Ya está todo numérico o ya fue procesado.\")\n",
        "else:\n",
        "    for col in object_cols_in_trans:\n",
        "        print(f\"\\nColumna: '{col}' (dtype: {df_trans[col].dtype})\")\n",
        "        unique_vals = df_trans[col].dropna().unique()\n",
        "\n",
        "        if len(unique_vals) < 50: # Mostrar todos los únicos si son pocos\n",
        "            print(\"Valores únicos (muestra pequeña):\", unique_vals)\n",
        "        else: # Mostrar una muestra aleatoria si hay muchos\n",
        "            print(f\"Total de valores únicos: {len(unique_vals)}. Muestra aleatoria:\")\n",
        "            print(np.random.choice(unique_vals, 20, replace=False))\n",
        "\n",
        "        # Intentar inferir si podría ser numérico\n",
        "        numeric_like_count = df_trans[col].astype(str).str.contains(r'[0-9]', na=False).sum()\n",
        "        if numeric_like_count > 0 and numeric_like_count < len(df_trans[col].dropna()):\n",
        "            print(f\"  -> Contiene {numeric_like_count} valores que parecen numéricos/mixtos (de {len(df_trans[col].dropna())} no nulos).\")\n",
        "        elif numeric_like_count == len(df_trans[col].dropna()) and len(df_trans[col].dropna()) > 0:\n",
        "            print(f\"  -> Todos los {len(df_trans[col].dropna())} valores no nulos parecen numéricos.\")\n",
        "        else:\n",
        "            print(\"  -> No contiene valores que parezcan numéricos en los no nulos.\")\n",
        "\n",
        "print(\"\\n--- Análisis de columnas completado. ---\")\n",
        "print(\"Basado en esta revisión, se pueden identificar las columnas 'object' que deban ser convertidas a numéricas.\")\n"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Columnas con dtype 'object' en df_trans y muestra de valores ---\n",
            "\n",
            "Columna: 'REGION' (dtype: object)\n",
            "Valores únicos (muestra pequeña): ['Norte' 'Sur' 'Otra']\n",
            "  -> No contiene valores que parezcan numéricos en los no nulos.\n",
            "\n",
            "Columna: 'N°' (dtype: object)\n",
            "Total de valores únicos: 325. Muestra aleatoria:\n",
            "[252 225 322 156 223 268 166 43 224 230 272 106 247 316 189 58 16 50 175\n",
            " 124]\n",
            "  -> Todos los 325 valores no nulos parecen numéricos.\n",
            "\n",
            "Columna: 'NOMBRE' (dtype: object)\n",
            "Total de valores únicos: 314. Muestra aleatoria:\n",
            "['Huemules' 'Meseta Central' 'Buitrera' 'San Francisco' 'Inca Viejo'\n",
            " 'Sierra Pintada ' 'Altos Del Cura' 'Sor Rafaela' 'Unchimé' 'Cerro Negro'\n",
            " 'Distrito Gonzalito' 'Taguas' 'El Duende' 'Solaroz'\n",
            " 'Margarita (Zorriquin)' 'Salar del Rincón' 'Cauchari-Olaroz' 'Diablillos'\n",
            " 'Formentera-Cilón' 'Picaso']\n",
            "  -> Contiene 3 valores que parecen numéricos/mixtos (de 325 no nulos).\n",
            "\n",
            "Columna: 'CONTROLANTE (1°)' (dtype: object)\n",
            "Total de valores únicos: 144. Muestra aleatoria:\n",
            "['Eris LLC' 'Origen Resources Inc.' 'Hochschild Mining Plc' 'McEwen Inc.'\n",
            " 'Espíritu de los Andes S.A.' 'Fortescue  Ltd.' 'POSCO Holdings Inc. '\n",
            " 'Udine S.A.' 'Diego Ruben Omar' 'Cascadero Copper Corp.'\n",
            " 'Cosmos Minerals S.A.' 'Cardero Resource Corp,' 'Ekeko S.A'\n",
            " 'Patagonia Gold' 'Aguilar Polimetalica'\n",
            " 'Minera Anglo American Argentina S.A.' 'Unico Silver Ltda.'\n",
            " 'Glencore Plc.' 'Patagonia Gold ' 'Lithium S. Corporation']\n",
            "  -> Contiene 2 valores que parecen numéricos/mixtos (de 228 no nulos).\n",
            "\n",
            "Columna: 'PORCENTAJE (1°)' (dtype: object)\n",
            "Valores únicos (muestra pequeña): [1.0 0.8 0.65 0.95 0.467 0.925 0.5 0.75 0.9 0.47 0.67 0.85 0.7 0.46 0.51\n",
            " 0.6 0.501]\n",
            "  -> Todos los 203 valores no nulos parecen numéricos.\n",
            "\n",
            "Columna: 'ORIGEN (1°)' (dtype: object)\n",
            "Valores únicos (muestra pequeña): ['Argentina' 'Canadá' 'Argentina ' 'China' 'Australia' 'Canadá '\n",
            " 'Estados Unidos ' 'Reino Unido' 'Francia' 'Estados Unidos' 'Sudáfrica'\n",
            " 'Suiza' 'Australia ' 'Corea del Sur' 'Paises Bajos ' 'China ']\n",
            "  -> No contiene valores que parezcan numéricos en los no nulos.\n",
            "\n",
            "Columna: 'CONTROLANTE (2°)' (dtype: object)\n",
            "Valores únicos (muestra pequeña): ['Sibanye Stillwater' '-' 'SMG S.R.L.' 'NewPeak Metals Limited' 'Fomicruz'\n",
            " 'Lithium Argentina' 'AbraSilver Corp.' 'Sable Resources Ltd.'\n",
            " 'Deseado Dorado S. A. S.' 'BHP Group Corp.' 'BHP Group '\n",
            " 'Lilac Solutions Inc.' 'Shandong Gold Mining' 'Stellantis'\n",
            " 'Toyota Tsusho' 'Latin Metals Inc.' 'Ganfeng Lithium'\n",
            " 'Compañía Minera Piuquenes S.A.' 'Regberg Ltd.'\n",
            " 'Tibet Summit Resources Co., Ltd' 'Grupo Alberdi' 'McEwen Mining Inc.'\n",
            " 's/n' 'CAM' 'Minsud Resources Corp.' 'Shandong Gold Mining Co. Ltd.']\n",
            "  -> No contiene valores que parezcan numéricos en los no nulos.\n",
            "\n",
            "Columna: 'ORIGEN (2°)' (dtype: object)\n",
            "Valores únicos (muestra pequeña): ['Sudáfrica' '-' 'Argentina' 'Australia' 'Canadá' 'Estados Unidos' 'China'\n",
            " 'Países Bajos' 'Japón' 49.9]\n",
            "  -> Contiene 1 valores que parecen numéricos/mixtos (de 92 no nulos).\n",
            "\n",
            "Columna: 'PORCENTAJE (2°)' (dtype: object)\n",
            "Valores únicos (muestra pequeña): [0.2 0.35 0.05 0.448 0.075 0.5 0.25 0.1 0.19 0.15 0.3 0.45 0.49 0.4]\n",
            "  -> Todos los 30 valores no nulos parecen numéricos.\n",
            "\n",
            "Columna: 'CONTROLANTE (3°)' (dtype: object)\n",
            "Valores únicos (muestra pequeña): ['-' 'Jujuy Energia y Mineria' 'Otros' 'Jujuy Energía y Minería'\n",
            " 'Leading Resources Global Ltd.']\n",
            "  -> No contiene valores que parezcan numéricos en los no nulos.\n",
            "\n",
            "Columna: 'PORCENTAJE (3°)' (dtype: object)\n",
            "Valores únicos (muestra pequeña): [0.085 0.33 0.09]\n",
            "  -> Todos los 4 valores no nulos parecen numéricos.\n",
            "\n",
            "Columna: 'ORIGEN (3°)' (dtype: object)\n",
            "Valores únicos (muestra pequeña): ['-' 'Argentina' 'Reino Unido']\n",
            "  -> No contiene valores que parezcan numéricos en los no nulos.\n",
            "\n",
            "Columna: 'Unnamed: 16' (dtype: object)\n",
            "Valores únicos (muestra pequeña): ['Bombeo - La salmuera es bombeada desde los acuíferos hacia las piletas de evaporación, la cual luego pasa a un proceso químico en la planta para lograr la concentración adecuada.']\n",
            "  -> No contiene valores que parezcan numéricos en los no nulos.\n",
            "\n",
            "--- Análisis de columnas completado. ---\n",
            "Basado en esta revisión, se pueden identificar las columnas 'object' que deban ser convertidas a numéricas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5caa8531",
        "outputId": "6b2a3815-2778-4cfa-fda9-3b7753137f7d"
      },
      "source": [
        "# 4.F Coerción y Eliminación de columnas restantes de tipo 'object'\n",
        "\n",
        "# Convertir 'N°' a int64\n",
        "# Manejar posibles NaN si los hubiera antes de la conversión a int, aunque el análisis mostró 0 nulos.\n",
        "if 'N°' in df_trans.columns:\n",
        "    df_trans['N°'] = pd.to_numeric(df_trans['N°'], errors='coerce').astype('Int64') # Usar Int64 para soportar NaN\n",
        "    print(\"Columna 'N°' convertida a Int64.\")\n",
        "else:\n",
        "    print(\"Columna 'N°' no encontrada en df_trans.\")\n",
        "\n",
        "# Columnas de porcentaje originales a eliminar por redundancia\n",
        "redundant_pct_cols = [c for c in ['PORCENTAJE (1°)', 'PORCENTAJE (2°)', 'PORCENTAJE (3°)'] if c in df_trans.columns]\n",
        "if redundant_pct_cols:\n",
        "    df_trans = df_trans.drop(columns=redundant_pct_cols)\n",
        "    print(f\"Columnas redundantes de porcentaje eliminadas: {redundant_pct_cols}\")\n",
        "else:\n",
        "    print(\"No se encontraron columnas de porcentaje redundantes a eliminar.\")\n",
        "\n",
        "# Eliminar columna 'Unnamed: 16' si existe\n",
        "unnamed_col = 'Unnamed: 16'\n",
        "if unnamed_col in df_trans.columns:\n",
        "    df_trans = df_trans.drop(columns=[unnamed_col])\n",
        "    print(f\"Columna '{unnamed_col}' eliminada.\")\n",
        "else:\n",
        "    print(f\"Columna '{unnamed_col}' no encontrada en df_trans.\")\n",
        "\n",
        "print(\"\\n--- Revisión final de columnas 'object' restantes ---\")\n",
        "object_cols_final = df_trans.select_dtypes(include='object').columns\n",
        "if len(object_cols_final) == 0:\n",
        "    print(\"¡No hay columnas con dtype 'object' en df_trans! Todas han sido procesadas o son numéricas.\")\n",
        "else:\n",
        "    print(\"Columnas 'object' restantes (son features categóricas textuales):\")\n",
        "    for col in object_cols_final:\n",
        "        print(f\"- {col}\")\n",
        "\n",
        "print(\"\\n--- Resumen de df_trans después de las últimas coerciones ---\")\n",
        "print(f\"Filas: {df_trans.shape[0]} | Columnas: {df_trans.shape[1]}\")\n",
        "print(\"Dtypes actualizados (muestra):\")\n",
        "print(df_trans.dtypes.apply(lambda x: x.name).to_string())"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columna 'N°' convertida a Int64.\n",
            "Columnas redundantes de porcentaje eliminadas: ['PORCENTAJE (1°)', 'PORCENTAJE (2°)', 'PORCENTAJE (3°)']\n",
            "Columna 'Unnamed: 16' eliminada.\n",
            "\n",
            "--- Revisión final de columnas 'object' restantes ---\n",
            "Columnas 'object' restantes (son features categóricas textuales):\n",
            "- REGION\n",
            "- NOMBRE\n",
            "- CONTROLANTE (1°)\n",
            "- ORIGEN (1°)\n",
            "- CONTROLANTE (2°)\n",
            "- ORIGEN (2°)\n",
            "- CONTROLANTE (3°)\n",
            "- ORIGEN (3°)\n",
            "\n",
            "--- Resumen de df_trans después de las últimas coerciones ---\n",
            "Filas: 325 | Columnas: 24\n",
            "Dtypes actualizados (muestra):\n",
            "num_LATITUD                  float64\n",
            "num_LONGITUD                 float64\n",
            "num_PORCENTAJE (1°)_clean    float64\n",
            "num_PORCENTAJE (2°)_clean    float64\n",
            "num_PORCENTAJE (3°)_clean    float64\n",
            "ESTADO_ORD                   float64\n",
            "REGION                        object\n",
            "mineral_Cobre                  int64\n",
            "mineral_Litio                  int64\n",
            "mineral_Oro                    int64\n",
            "mineral_Plata                  int64\n",
            "mineral_Plomo                  int64\n",
            "mineral_Uranio                 int64\n",
            "mineral_Hierro                 int64\n",
            "mineral_Manganeso              int64\n",
            "mineral_Otros                  int64\n",
            "N°                             Int64\n",
            "NOMBRE                        object\n",
            "CONTROLANTE (1°)              object\n",
            "ORIGEN (1°)                   object\n",
            "CONTROLANTE (2°)              object\n",
            "ORIGEN (2°)                   object\n",
            "CONTROLANTE (3°)              object\n",
            "ORIGEN (3°)                   object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "935e84c6"
      },
      "source": [
        "## Conclusiones Finales: Features y Preprocesado Reproducible\n",
        "\n",
        "Esta sección ha consolidado y refinado el proceso de preparación de datos, resultando en un dataset `df_trans` completamente preprocesado y listo para la fase de modelado. Los logros clave incluyen:\n",
        "\n",
        "1.  **Limpieza y Normalización Inicial de Datos:**\n",
        "    *   **Columnas de Porcentaje:** Las columnas `PORCENTAJE (1°)`, `PORCENTAJE (2°)` y `PORCENTAJE (3°)` fueron inicialmente limpiadas de caracteres no numéricos y convertidas a tipo `float`. Sus versiones originales (`PORCENTAJE (n°)`) fueron posteriormente eliminadas, dejando solo las versiones limpias y escaladas (`num_PORCENTAJE (n°)_clean`) para evitar redundancia y ambigüedad.\n",
        "    *   **Columnas Residuales:** La columna `Unnamed: 16`, identificada como un residuo con valores vacíos o irrelevantes, fue eliminada para limpiar el dataset.\n",
        "    *   **Coerción de Tipos de Identificadores:** La columna `'N°'`, que representaba un identificador numérico pero estaba como `object`, se convirtió explícitamente a `Int64` para asegurar su correcto tipo y manejo de posibles nulos.\n",
        "\n",
        "2.  **Ingeniería de Features Específica del Dominio:**\n",
        "    *   **Codificación Ordinal de `ESTADO`:** Se creó la columna `ESTADO_ORD` transformando la variable categórica `ESTADO` en una representación numérica ordenada, reflejando la progresión natural de las fases de un proyecto minero (Prospección < Exploración < Desarrollo < Producción). Esto permite a los modelos capturar la ordinalidad inherente.\n",
        "    *   **Agrupación Regional (`REGION`):** A partir de la columna `PROVINCIA`, se derivó una nueva característica `REGION` (Norte, Centro, Sur, Otra, Desconocido). Esto reduce la cardinalidad de la variable geográfica, agrupa provincias con características similares y ayuda a capturar patrones regionales más generales.\n",
        "    *   **Codificación de `MINERAL PRINCIPAL`:** Esta variable categórica se procesó mediante un esquema de 'one-hot encoding' (`mineral_Cobre`, `mineral_Litio`, etc.). Se utilizó una estrategia de `top-k` (los 8 minerales más frecuentes) y el resto se agrupó en una categoría 'Otros', evitando la explosión de dimensionalidad y permitiendo a los modelos interpretar la presencia de tipos de mineral.\n",
        "\n",
        "3.  **Estandarización de Features Numéricas:**\n",
        "    *   Las columnas numéricas como `LATITUD`, `LONGITUD` y los `PORCENTAJES` limpios (`num_PORCENTAJE (n°)_clean`) fueron imputadas (con la mediana para manejar nulos) y escaladas utilizando `StandardScaler`. Esto asegura que todas las características numéricas tengan una media de cero y una varianza unitaria, lo que es crucial para el buen desempeño de muchos algoritmos de aprendizaje automático.\n",
        "\n",
        "4.  **Pipeline Compacto y Robusto (`scikit-learn`):**\n",
        "    *   Se construyó y ajustó un `Pipeline` con `ColumnTransformer` que encapsula todas las transformaciones anteriores de manera modular y reproducible. Este diseño permite aplicar consistentemente el mismo conjunto de pasos a cualquier nuevo dato y es fundamental para la validación cruzada y la inferencia en producción.\n",
        "    *   Se resolvieron errores clave como `AttributeError: 'DataFrame' object has no attribute 'ravel'` y `ValueError` relacionados con la forma de las entradas a los transformadores, así como `PicklingError` y `TypeError` asociados a la serialización de componentes personalizados (`lambda` y clases anidadas), haciendo el pipeline robusto y serializable.\n",
        "\n",
        "5.  **Reconstrucción y Verificación del `DataFrame` Final:**\n",
        "    *   La salida del `ColumnTransformer` (un array NumPy) fue meticulosamente reconstruida en un `DataFrame` (`df_trans`) con nombres de columna legibles (`num_LATITUD`, `ESTADO_ORD`, `REGION`, `mineral_Cobre`, etc.) y tipos de datos correctos. Esta reconstrucción es vital para la interpretabilidad y para asegurar que el `DataFrame` esté listo para las siguientes fases.\n",
        "\n",
        "6.  **Persistencia de Artefactos:** El `fitted_pipeline` (pipeline ajustado) y `maps` (diccionarios de mapeo para estados, top-k minerales) se han guardado con `joblib` y `json` en `data/artifacts`. Esto garantiza la reproducibilidad completa del preprocesamiento, permitiendo recargar el modelo y aplicar las mismas transformaciones sin necesidad de reentrenar o recalcular los mapeos.\n",
        "\n",
        "El `df_trans` final, con **325 filas y 24 columnas**, es un conjunto de datos estandarizado, limpio, con las características diseñadas, y con los tipos de datos correctos, listo para alimentar los modelos de clasificación y abordar el objetivo de predecir la etapa avanzada de los proyectos mineros."
      ]
    }
  ]
}