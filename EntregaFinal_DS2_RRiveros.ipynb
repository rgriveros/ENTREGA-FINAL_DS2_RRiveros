{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNelA13ZdGhf/c+yH6YUwkW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rgriveros/ENTREGA-FINAL_DS2_RRiveros/blob/main/EntregaFinal_DS2_RRiveros.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EntregaFinal — Proyectos Mineros en Argentina**\n",
        "## Autor: **Gabriel Riveros Lobos**  \n",
        "## Fecha: 13/11/2025  \n",
        "## Objetivo del notebook: **Predecir si un proyecto minero alcanza etapa avanzada (clasificación binaria).**  \n",
        "## Métrica principal: AUC (Area Under ROC).  \n",
        "\n",
        "## **Contexto:**\n",
        "Cartera de proyectos mineros con atributos técnicos, geográficos y de propiedad. Los equipos de evaluación y toma de decisiones necesitan priorizar recursos y planificar inversiones.\n",
        "\n",
        "## **Objetivo:**\n",
        "Construir un modelo de clasificación para predecir si un proyecto alcanzará una etapa avanzada (sí/no), facilitando priorización de inversión y asignación de recursos operativos.\n",
        "Pregunta de negocio: ¿Qué proyectos de la cartera tienen alta probabilidad de alcanzar una etapa avanzada y, por tanto, merecen priorización de inversión?\n",
        "\n",
        "## **Audiencia beneficiada:**\n",
        "Gerencias de proyectos, analistas de cartera e inversores que requieren señales tempranas sobre proyectos con mayor probabilidad de avance.\n",
        "\n",
        "## **Métrica principal:**\n",
        "AUC ROC — elegida por su robustez ante desequilibrios en clases y porque mide la capacidad global del modelo para distinguir proyectos que avanzan de los que no.\n",
        "\n",
        "### Justificación corta de la métrica\n",
        "AUC ROC está indicada porque: Maneja bien clases desbalanceadas sin requerir un umbral fijo. Permite comparar modelos independientemente del coste asociado a falsos positivos/negativos; luego se puede fijar umbral según trade-off operativo.\n",
        "\n",
        "## **Resumen ejecutivo:**\n",
        "Este notebook presenta la carga y limpieza de datos, la ingeniería de features, la comparación de modelos (baseline vs tree-based), la optimización ligera de hiperparámetros y la explicación del modelo final con SHAP. El entregable incluye el modelo final serializado, métricas comparativas y recomendaciones operativas para priorizar la cartera.\n",
        "\n",
        "\n",
        "---\n",
        "## **Instrucciones rápidas:**  \n",
        "Clonar el repo.\n",
        "pip install -r requirements.txt..\n",
        "Ejecutar la celda \"2 — Preparación\" del notebook (descarga automática vía CKAN y guarda data/dataset.csv).\n"
      ],
      "metadata": {
        "id": "Gb-a7bzFMUBc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Requisitos, entorno y reproducibilidad\n",
        "\n",
        "Objetivo: dejar configurado el entorno mínimo necesario para que el notebook sea reproducible y ejecutable en Colab y en cualquier máquina local con Python. Esto incluye:\n",
        "- Declarar y fijar la semilla global (RANDOM_STATE).\n",
        "- Importar librerías clave y mostrar versiones para trazabilidad.\n",
        "- Definir y crear la estructura de carpetas usada por el proyecto.\n",
        "- Generar archivos iniciales: `README_colab.txt` y `data/sample_input.csv` (muestra vacía), listos para subir al repo.\n",
        "\n"
      ],
      "metadata": {
        "id": "hK1dh2ssejCr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.2 Imports, seed, paths y creación de estructura\n",
        "import sys, os, platform\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib, matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "import joblib\n",
        "from datetime import datetime\n",
        "\n",
        "# Semilla reproducible\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "\n",
        "# Imprimir versiones clave para reproducibilidad\n",
        "print(\"Python:\", sys.version.splitlines()[0])\n",
        "print(\"Platform:\", platform.platform())\n",
        "print(\"NumPy:\", np.__version__)\n",
        "print(\"Pandas:\", pd.__version__)\n",
        "print(\"Matplotlib:\", matplotlib.__version__)\n",
        "print(\"Seaborn:\", sns.__version__)\n",
        "print(\"Scikit-learn:\", sklearn.__version__)\n",
        "print(\"Joblib:\", joblib.__version__)\n",
        "print(\"RANDOM_STATE set to\", RANDOM_STATE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rC7tq5LSevU2",
        "outputId": "bab7afa8-698f-40ad-e491-7be0acbe698e"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
            "Platform: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "NumPy: 2.0.2\n",
            "Pandas: 2.2.2\n",
            "Matplotlib: 3.10.0\n",
            "Seaborn: 0.13.2\n",
            "Scikit-learn: 1.6.1\n",
            "Joblib: 1.5.2\n",
            "RANDOM_STATE set to 42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carga de Datos y chequeo rápido EDA\n",
        "\n",
        "Objetivo:\n",
        "\n",
        "Esta celda descarga el dataset público desde la API CKAN de datos.gob.ar (package_search → package_show → recurso CSV/XLSX), guarda el archivo en la carpeta local data/ del repositorio y genera un snapshot local para trazabilidad. No requiere acceso a Google Drive. Variables editables: QUERY, ROWS, VERIFY_SSL. Mantener VERIFY_SSL = True; usar False solo si el entorno falla por certificado (documentar el uso). Dependencias: requests, pandas, openpyxl (si hay Excel).\n"
      ],
      "metadata": {
        "id": "Xgjtjt-DRa6C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Descarga por API CKAN -> guarda en ./data/ -> lee y snapshot\n",
        "import requests\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# ---------- EDITAR SOLO ESTAS VARIABLES ----------\n",
        "CKAN_BASE = \"https://datos.gob.ar/api/3/action\"\n",
        "QUERY = \"Proyectos mineros metalíferos y de litio\"\n",
        "ROWS = 5\n",
        "VERIFY_SSL = False   # True recomendado; False solo si hay error certificado y lo documentás\n",
        "# -------------------------------------------------\n",
        "\n",
        "DATA_DIR = Path(\"data\")\n",
        "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def ck_search_and_download(query, rows=5, verify_ssl=True, retries=2, backoff=2):\n",
        "    for attempt in range(retries + 1):\n",
        "        try:\n",
        "            r = requests.get(f\"{CKAN_BASE}/package_search\", params={\"q\": query, \"rows\": rows}, timeout=30, verify=verify_ssl)\n",
        "            r.raise_for_status()\n",
        "            results = r.json().get(\"result\", {}).get(\"results\", [])\n",
        "            if not results:\n",
        "                raise FileNotFoundError(f\"No se encontraron paquetes para la query: '{query}'\")\n",
        "            first = results[0]\n",
        "            pkg_id = first.get(\"id\") or first.get(\"name\")\n",
        "            r2 = requests.get(f\"{CKAN_BASE}/package_show\", params={\"id\": pkg_id}, timeout=30, verify=verify_ssl)\n",
        "            r2.raise_for_status()\n",
        "            pkg = r2.json().get(\"result\", {})\n",
        "            resources = pkg.get(\"resources\", []) or []\n",
        "            for res in resources:\n",
        "                url = (res.get(\"url\") or \"\").strip()\n",
        "                if url.lower().endswith((\".csv\", \".xlsx\", \".xls\")):\n",
        "                    return pkg, url\n",
        "            raise FileNotFoundError(\"No se encontró recurso CSV/XLSX en el paquete seleccionado.\")\n",
        "        except (requests.RequestException, ValueError) as e:\n",
        "            if attempt < retries:\n",
        "                time.sleep(backoff * (attempt + 1))\n",
        "                continue\n",
        "            raise RuntimeError(f\"Fallo al consultar CKAN: {e}\")\n",
        "\n",
        "pkg_meta, res_url = ck_search_and_download(QUERY, ROWS, VERIFY_SSL)\n",
        "\n",
        "dst = DATA_DIR / (\"dataset_minero.csv\" if res_url.lower().endswith(\".csv\") else \"dataset_minero.xlsx\")\n",
        "with requests.get(res_url, stream=True, timeout=120, verify=VERIFY_SSL) as resp:\n",
        "    resp.raise_for_status()\n",
        "    with open(dst, \"wb\") as f:\n",
        "        for chunk in resp.iter_content(8192):\n",
        "            if chunk:\n",
        "                f.write(chunk)\n",
        "\n",
        "if dst.suffix.lower() == \".csv\":\n",
        "    df = pd.read_csv(dst, low_memory=False, encoding=\"utf-8\")\n",
        "else:\n",
        "    df = pd.read_excel(dst, engine=\"openpyxl\")\n",
        "\n",
        "# Guardar snapshot para trazabilidad\n",
        "snapshot = DATA_DIR / \"data_snapshot_head.csv\"\n",
        "df.head(200).to_csv(snapshot, index=False)\n",
        "\n",
        "# Salida mínima y reproducible\n",
        "print(\"Package:\", pkg_meta.get(\"title\") or pkg_meta.get(\"name\"))\n",
        "print(\"Fuente (URL):\", res_url)\n",
        "print(\"Guardado en:\", dst)\n",
        "print(\"Filas:\", df.shape[0], \"| Columnas:\", df.shape[1])\n",
        "print(df.isna().sum().sort_values(ascending=False).head(20).to_string())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6TBvK35A2lC",
        "outputId": "6f7643f0-80ed-4d95-8491-531175818a91"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'datos.gob.ar'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'datos.gob.ar'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.mecon.gob.ar'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.economia.gob.ar'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Package: Cartera de Proyectos Mineros en Argentina del SIACAM\n",
            "Fuente (URL): https://www.mecon.gob.ar/dataset/Cartera-de-Proyectos-Mineros-Metaliferos-y-Litio-del-SIACAM.xlsx\n",
            "Guardado en: data/dataset_minero.xlsx\n",
            "Filas: 325 | Columnas: 17\n",
            "Unnamed: 16          324\n",
            "PORCENTAJE (3°)      235\n",
            "ORIGEN (2°)          233\n",
            "ORIGEN (3°)          232\n",
            "CONTROLANTE (3°)     232\n",
            "CONTROLANTE (2°)     231\n",
            "PORCENTAJE (2°)      229\n",
            "PORCENTAJE (1°)      122\n",
            "ORIGEN (1°)          121\n",
            "CONTROLANTE (1°)      97\n",
            "N°                     0\n",
            "PROVINCIA              0\n",
            "ESTADO                 0\n",
            "LATITUD                0\n",
            "NOMBRE                 0\n",
            "LONGITUD               0\n",
            "MINERAL PRINCIPAL      0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Guardando metadatos del paquete (id, title, url, fecha de descarga) para trazabilidad reproducible"
      ],
      "metadata": {
        "id": "Nx2b1ltSD-e9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar metadatos del paquete\n",
        "import json\n",
        "from datetime import datetime, timezone\n",
        "from pathlib import Path\n",
        "\n",
        "META_PATH = Path(\"data\")\n",
        "META_PATH.mkdir(parents=True, exist_ok=True)\n",
        "OUT = META_PATH / \"dataset_metadata.json\"\n",
        "\n",
        "def safe_str(x):\n",
        "    try:\n",
        "        return str(x)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "meta = {\n",
        "    \"package_id\": safe_str(pkg_meta.get(\"id\") if isinstance(pkg_meta, dict) else pkg_meta),\n",
        "    \"package_title\": safe_str(pkg_meta.get(\"title\") if isinstance(pkg_meta, dict) else pkg_meta),\n",
        "    \"resource_url\": safe_str(res_url),\n",
        "    \"downloaded_at\": datetime.now(timezone.utc).isoformat()\n",
        "}\n",
        "\n",
        "try:\n",
        "    with open(OUT, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(meta, f, ensure_ascii=False, indent=2)\n",
        "    print(\"Metadatos guardados en:\", OUT)\n",
        "except Exception as e:\n",
        "    print(\"Error al guardar metadatos:\", type(e).__name__, \"-\", e)\n",
        "    print(\"Contenido meta (fallback):\", {k: v for k, v in meta.items()})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLJWgf6uDsEf",
        "outputId": "9a24a5b0-ff2a-48bd-9883-ac8ba780d917"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metadatos guardados en: data/dataset_metadata.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.dtypes)\n",
        "print(df.head(5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ks5oEBaXEFIe",
        "outputId": "610beae5-4aea-4e67-8099-bb37855f7b53"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N°                     int64\n",
            "NOMBRE                object\n",
            "LATITUD              float64\n",
            "LONGITUD             float64\n",
            "MINERAL PRINCIPAL     object\n",
            "PROVINCIA             object\n",
            "ESTADO                object\n",
            "CONTROLANTE (1°)      object\n",
            "PORCENTAJE (1°)      float64\n",
            "ORIGEN (1°)           object\n",
            "CONTROLANTE (2°)      object\n",
            "ORIGEN (2°)           object\n",
            "PORCENTAJE (2°)       object\n",
            "CONTROLANTE (3°)      object\n",
            "PORCENTAJE (3°)       object\n",
            "ORIGEN (3°)           object\n",
            "Unnamed: 16           object\n",
            "dtype: object\n",
            "   N°             NOMBRE  LATITUD  LONGITUD MINERAL PRINCIPAL  PROVINCIA  \\\n",
            "0   1  20 de septiembre   -24.896   -68.136            Hierro      Salta   \n",
            "1   2           Acazoque  -24.291   -66.378             Plomo      Salta   \n",
            "2   3   Acoite/Hornillos  -22.305   -65.107             Plomo      Salta   \n",
            "3   4              Adamo  -41.162   -68.505               Oro  Río Negro   \n",
            "4   5      Aguas Amargas  -24.685   -66.903             Cobre      Salta   \n",
            "\n",
            "                ESTADO        CONTROLANTE (1°)  PORCENTAJE (1°) ORIGEN (1°)  \\\n",
            "0  Exploración inicial        Diego Ruben Omar              NaN         NaN   \n",
            "1  Exploración inicial             Nuñez Ramon              NaN         NaN   \n",
            "2  Exploración inicial  Rubiolo Daniel Gerardo              NaN         NaN   \n",
            "3          Prospección  Valcheta Exploraciones              1.0   Argentina   \n",
            "4  Exploración inicial     Lithium S Corp. S.A              NaN         NaN   \n",
            "\n",
            "  CONTROLANTE (2°) ORIGEN (2°) PORCENTAJE (2°) CONTROLANTE (3°)  \\\n",
            "0              NaN         NaN             NaN              NaN   \n",
            "1              NaN         NaN             NaN              NaN   \n",
            "2              NaN         NaN             NaN              NaN   \n",
            "3              NaN         NaN             NaN              NaN   \n",
            "4              NaN         NaN             NaN              NaN   \n",
            "\n",
            "  PORCENTAJE (3°) ORIGEN (3°) Unnamed: 16  \n",
            "0             NaN         NaN         NaN  \n",
            "1             NaN         NaN         NaN  \n",
            "2             NaN         NaN         NaN  \n",
            "3             NaN         NaN         NaN  \n",
            "4             NaN         NaN         NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Observación rápida sobre la salida\n",
        "La lectura funcionó, pero hay columnas que deberían ser numéricas (p. ej. las columnas PORCENTAJE (...)) y aparecen como object — eso suele pasar por valores mezclados (cadenas, comas decimales, símbolos % o celdas vacías/extrañas).\n",
        "\n",
        "Hay una columna Unnamed: 16 vacía en su mayoría — probable columna residual del Excel que conviene eliminar.\n",
        "\n",
        "Latitud/Longitud ya son float64 (bien).\n",
        "\n",
        "Antes de cualquier análisis sería conveniente:\n",
        "1) inspeccionar las celdas “problemáticas”,\n",
        "2) normalizar formatos numéricos,\n",
        "3) convertir a tipos correctos\n",
        "4) registrar los cambios (snapshot + metadata)."
      ],
      "metadata": {
        "id": "Nc6JhJ3vGK4F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Limpieza y Manejo de Valores Faltantes"
      ],
      "metadata": {
        "id": "8tcdhb0UGx-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sección 4: Limpieza no destructiva -> guarda clean CSV, snapshot y metadata ampliada\n",
        "import re, json, time\n",
        "from pathlib import Path\n",
        "from datetime import datetime, timezone\n",
        "import pandas as pd\n",
        "\n",
        "# ----- Ajustar si fuera necesario -----\n",
        "DATA_DIR = Path(\"data\")\n",
        "RAW_FN = DATA_DIR / \"dataset_minero.xlsx\"   # cambiar si el raw tiene otro nombre\n",
        "OUT_CSV = DATA_DIR / \"dataset_minero_clean.csv\"\n",
        "SNAPSHOT_CSV = DATA_DIR / \"data_snapshot_head_clean.csv\"\n",
        "META_F = DATA_DIR / \"dataset_metadata.json\"\n",
        "# -------------------------------------\n",
        "\n",
        "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 0) cargar (si df ya existe en memoria, lo reutiliza)\n",
        "if 'df' not in globals():\n",
        "    if RAW_FN.exists():\n",
        "        if RAW_FN.suffix.lower() == \".csv\":\n",
        "            df = pd.read_csv(RAW_FN, low_memory=False, encoding=\"utf-8\")\n",
        "        else:\n",
        "            df = pd.read_excel(RAW_FN, engine=\"openpyxl\")\n",
        "    else:\n",
        "        raise FileNotFoundError(f\"Archivo raw no encontrado: {RAW_FN}\")"
      ],
      "metadata": {
        "id": "wNcNJJgKG7mK"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# 1) detectar columnas objetivo\n",
        "pct_cols = [c for c in df.columns if \"PORCENTAJE\" in str(c).upper()]\n",
        "obj_cols = [c for c in df.columns if df[c].dtype == \"object\" and c not in pct_cols]\n",
        "\n",
        "print(\"Columnas detectadas como PORCENTAJE:\", pct_cols)\n",
        "print(\"Ejemplo de columnas object detectadas:\", obj_cols[:8])\n",
        "\n",
        "# 2) limpieza helper (devuelve float o None)\n",
        "def clean_numeric_value(x):\n",
        "    if pd.isna(x):\n",
        "        return None\n",
        "    s = str(x).strip()\n",
        "    if s == \"\" or s in (\"-\", \"--\"):\n",
        "        return None\n",
        "    s = s.replace(\"\\xa0\", \"\").replace(\" \", \"\")\n",
        "    # quitar texto no numérico salvo signos, decimales, exp y %\n",
        "    s = re.sub(r\"[^\\d\\-,.\\+eE%]\", \"\", s)\n",
        "    if s == \"\" or s in (\"-\", \"--\"):\n",
        "        return None\n",
        "    is_pct = s.endswith(\"%\")\n",
        "    if is_pct:\n",
        "        s = s[:-1]\n",
        "    # manejar '.' y ',' coexistentes\n",
        "    if \",\" in s and \".\" in s:\n",
        "        if s.rfind(\",\") > s.rfind(\".\"):\n",
        "            s = s.replace(\".\", \"\").replace(\",\", \".\")\n",
        "        else:\n",
        "            s = s.replace(\",\", \"\")\n",
        "    else:\n",
        "        if \",\" in s and \".\" not in s:\n",
        "            s = s.replace(\",\", \".\")\n",
        "    try:\n",
        "        v = float(s)\n",
        "        # si era %, normalizar a 0-1; si nombre de columna indica porcentaje y v>1 asumimos 0-100->0-1\n",
        "        return v/100.0 if is_pct else v\n",
        "    except Exception:\n",
        "        return None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBT-zBcpG2g-",
        "outputId": "6d12b1e5-9252-48df-fcf4-ba43cfb823ae"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columnas detectadas como PORCENTAJE: ['PORCENTAJE (1°)', 'PORCENTAJE (2°)', 'PORCENTAJE (3°)']\n",
            "Ejemplo de columnas object detectadas: ['NOMBRE', 'MINERAL PRINCIPAL', 'PROVINCIA', 'ESTADO', 'CONTROLANTE (1°)', 'ORIGEN (1°)', 'CONTROLANTE (2°)', 'ORIGEN (2°)']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) aplicar a columnas PORCENTAJE y crear columnas *_clean (no sobreescribir)\n",
        "conversion_report = {}\n",
        "for c in pct_cols:\n",
        "    before = int(df[c].notna().sum())\n",
        "    cleaned = df[c].map(clean_numeric_value)\n",
        "    after = int(cleaned.notna().sum())\n",
        "    df[c + \"_clean\"] = cleaned\n",
        "    conversion_report[c] = {\"before_nonnull\": before, \"after_numeric\": after}\n",
        "\n",
        "# 4) opcional: aplicar a otras columnas object que el usuario confirme (aquí no se aplica por defecto)\n",
        "# Si querés convertir columnas adicionales, agrégalas a cols_to_convert\n",
        "cols_to_convert = []  # p. ej. [\"PORCENTAJE (2°)\"] si no fue detectada por nombre\n",
        "for c in cols_to_convert:\n",
        "    if c in df.columns:\n",
        "        before = int(df[c].notna().sum())\n",
        "        cleaned = df[c].map(clean_numeric_value)\n",
        "        after = int(cleaned.notna().sum())\n",
        "        df[c + \"_clean\"] = cleaned\n",
        "        conversion_report[c] = {\"before_nonnull\": before, \"after_numeric\": after}\n",
        "\n",
        "# 5) eliminar columnas vacías tipo Unnamed si están totalmente vacías\n",
        "unnamed = [c for c in df.columns if str(c).lower().startswith(\"unnamed\") and df[c].dropna().eq(\"\").all()]\n",
        "# además columnas con todos NaN\n",
        "allnan = [c for c in df.columns if df[c].isna().all()]\n",
        "drop_candidates = sorted(set(unnamed + allnan))\n",
        "if drop_candidates:\n",
        "    print(\"Columnas vacías a dropear (no destructivo todavía):\", drop_candidates)\n",
        "    df = df.drop(columns=drop_candidates, errors='ignore')"
      ],
      "metadata": {
        "id": "Qrfjm8r8HDuW"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6) guardar clean CSV y snapshot head\n",
        "df.to_csv(OUT_CSV, index=False, encoding=\"utf-8\")\n",
        "df.head(200).to_csv(SNAPSHOT_CSV, index=False, encoding=\"utf-8\")\n",
        "\n",
        "# 7) metadata ampliada\n",
        "meta = {\n",
        "    \"package_title\": pkg_meta.get(\"title\") if 'pkg_meta' in globals() else None,\n",
        "    \"package_id\": pkg_meta.get(\"id\") if 'pkg_meta' in globals() else None,\n",
        "    \"resource_url\": res_url if 'res_url' in globals() else None,\n",
        "    \"raw_file\": str(RAW_FN),\n",
        "    \"clean_file\": str(OUT_CSV),\n",
        "    \"snapshot_file\": str(SNAPSHOT_CSV),\n",
        "    \"generated_at\": datetime.now(timezone.utc).isoformat().replace(\"+00:00\",\"Z\"),\n",
        "    \"conversion_report\": conversion_report,\n",
        "    \"dropped_columns\": drop_candidates\n",
        "}\n",
        "with open(META_F, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(meta, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"Limpieza aplicada (no destructiva). Archivos creados:\")\n",
        "print(\" - Clean dataset:\", OUT_CSV)\n",
        "print(\" - Snapshot head:\", SNAPSHOT_CSV)\n",
        "print(\" - Metadata:\", META_F)\n",
        "print(\"\\nResumen conversion_report (porcentaje columnas):\")\n",
        "print(json.dumps(conversion_report, indent=2, ensure_ascii=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93c7kWFwHHIn",
        "outputId": "d2b0835c-f191-4c54-bfe6-aaab2f6dc727"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Limpieza aplicada (no destructiva). Archivos creados:\n",
            " - Clean dataset: data/dataset_minero_clean.csv\n",
            " - Snapshot head: data/data_snapshot_head_clean.csv\n",
            " - Metadata: data/dataset_metadata.json\n",
            "\n",
            "Resumen conversion_report (porcentaje columnas):\n",
            "{\n",
            "  \"PORCENTAJE (1°)\": {\n",
            "    \"before_nonnull\": 203,\n",
            "    \"after_numeric\": 203\n",
            "  },\n",
            "  \"PORCENTAJE (2°)\": {\n",
            "    \"before_nonnull\": 96,\n",
            "    \"after_numeric\": 30\n",
            "  },\n",
            "  \"PORCENTAJE (3°)\": {\n",
            "    \"before_nonnull\": 90,\n",
            "    \"after_numeric\": 4\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ¿Qué haremos y por qué?\n",
        "\n",
        "Crear un respaldo del dataset actual sin modificar (backup CSV) para preservar la fuente antes de cualquier cambio.\n",
        "\n",
        "Reemplazar cada columna original por su columna correspondiente con sufijo _clean (si existe) para aplicar la limpieza validada en la sección anterior. Mantendremos también las columnas _clean en el archivo final para trazabilidad.\n",
        "\n",
        "Guardar el dataset resultante como data/dataset_minero_clean_applied.csv y actualizar dataset_metadata.json con el registro de cambios (qué columnas se reemplazaron, conteos antes/después, timestamp y ruta del backup).\n",
        "\n",
        "### Beneficios y trazabilidad\n",
        "\n",
        "Reversibilidad: el respaldo permite restaurar el estado previo si detectás problemas más adelante.\n",
        "\n",
        "Auditoría: metadata contiene package id/title, resource_url, columnas reemplazadas y contadores, lo que facilita reproducir y auditar exactamente lo que se cambió.\n",
        "\n",
        "Seguridad para el revisor: la limpieza ya fue aplicada solo después de la inspección en Sección 3; aquí se realiza la operación irreversible controlada y documentada."
      ],
      "metadata": {
        "id": "bhSTseq0Iv5t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sección 4.1 Renombrar *_clean -> sobrescribir columnas originales con backup\n",
        "import json\n",
        "from pathlib import Path\n",
        "from datetime import datetime, timezone\n",
        "import pandas as pd\n",
        "import shutil\n",
        "\n",
        "DATA_DIR = Path(\"data\")\n",
        "RAW_FN = DATA_DIR / \"dataset_minero.xlsx\"\n",
        "BACKUP_RAW_CSV = DATA_DIR / \"dataset_minero_raw_backup.csv\"\n",
        "OUT_APPLIED = DATA_DIR / \"dataset_minero_clean_applied.csv\"\n",
        "META_F = DATA_DIR / \"dataset_metadata.json\"\n",
        "\n",
        "# 4.1.0) cargar df (si no existe en memoria lo leemos del clean intermedio o del raw)\n",
        "if 'df' not in globals():\n",
        "    # preferimos el clean intermedio si existe\n",
        "    candidate_clean = DATA_DIR / \"dataset_minero_clean.csv\"\n",
        "    if candidate_clean.exists():\n",
        "        df = pd.read_csv(candidate_clean, low_memory=False, encoding=\"utf-8\")\n",
        "    elif RAW_FN.exists():\n",
        "        if RAW_FN.suffix.lower() == \".csv\":\n",
        "            df = pd.read_csv(RAW_FN, low_memory=False, encoding=\"utf-8\")\n",
        "        else:\n",
        "            df = pd.read_excel(RAW_FN, engine=\"openpyxl\")\n",
        "    else:\n",
        "        raise FileNotFoundError(\"No se encontró ningún dataset intermedio ni raw para aplicar los cambios.\")"
      ],
      "metadata": {
        "id": "ZLZUMC3IJGRc"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.1.1) identificar columnas *_clean y sus originales\n",
        "clean_cols = [c for c in df.columns if isinstance(c, str) and c.endswith(\"_clean\")]\n",
        "mapping = {}\n",
        "for c in clean_cols:\n",
        "    orig = c[:-6]  # quitar sufijo \"_clean\"\n",
        "    if orig in df.columns:\n",
        "        mapping[orig] = c\n",
        "\n",
        "if not mapping:\n",
        "    raise RuntimeError(\"No se encontraron columnas *_clean que correspondan a columnas originales. Nada que aplicar.\")\n",
        "\n",
        "print(\"Columnas a reemplazar (original -> *_clean):\")\n",
        "for orig, clean in mapping.items():\n",
        "    print(f\" - {orig}  <-  {clean}\")\n",
        "\n",
        "# 4.1.2) crear backup CSV del estado actual (antes de aplicar)\n",
        "df.to_csv(BACKUP_RAW_CSV, index=False, encoding=\"utf-8\")\n",
        "print(\"Backup creado en:\", BACKUP_RAW_CSV)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXTPfAlVJLjH",
        "outputId": "121bbb32-68f2-4d9d-b062-dc890f5ee7c4"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columnas a reemplazar (original -> *_clean):\n",
            " - PORCENTAJE (1°)  <-  PORCENTAJE (1°)_clean\n",
            " - PORCENTAJE (2°)  <-  PORCENTAJE (2°)_clean\n",
            " - PORCENTAJE (3°)  <-  PORCENTAJE (3°)_clean\n",
            "Backup creado en: data/dataset_minero_raw_backup.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.1.3) aplicar reemplazo: para cada mapping, mover valores de columna_clean a columna original\n",
        "replaced = {}\n",
        "for orig, clean in mapping.items():\n",
        "    before_nonnull = int(df[orig].notna().sum()) if orig in df.columns else 0\n",
        "    # asignar valores limpios sobre la columna original\n",
        "    df[orig] = df[clean]\n",
        "    after_nonnull = int(df[orig].notna().sum())\n",
        "    replaced[orig] = {\"clean_column\": clean, \"before_nonnull\": before_nonnull, \"after_nonnull\": after_nonnull}\n",
        "\n",
        "# 4.1.4) guardar dataset final aplicado\n",
        "df.to_csv(OUT_APPLIED, index=False, encoding=\"utf-8\")\n",
        "print(\"Dataset final guardado en:\", OUT_APPLIED)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzLWQ2ljJVOd",
        "outputId": "a16955b4-519d-40da-9acb-c4f6bf85dcba"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset final guardado en: data/dataset_minero_clean_applied.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.1.5) actualizar metadata (leer la previa si existe y extenderla)\n",
        "meta = {}\n",
        "if META_F.exists():\n",
        "    try:\n",
        "        with open(META_F, \"r\", encoding=\"utf-8\") as f:\n",
        "            meta = json.load(f)\n",
        "    except Exception:\n",
        "        meta = {}\n",
        "\n",
        "meta_update = {\n",
        "    \"applied_at\": datetime.now(timezone.utc).isoformat().replace(\"+00:00\",\"Z\"),\n",
        "    \"backup_raw_csv\": str(BACKUP_RAW_CSV),\n",
        "    \"applied_file\": str(OUT_APPLIED),\n",
        "    \"columns_replaced\": replaced\n",
        "}\n",
        "meta.update(meta_update)\n",
        "\n",
        "with open(META_F, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(meta, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"\\nMetadata actualizada en:\", META_F)\n",
        "print(\"Resumen cambios:\")\n",
        "import pprint\n",
        "pprint.pprint(replaced)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87u6FxOZJWVP",
        "outputId": "234ec485-9384-4e04-814f-19ae2b47408c"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Metadata actualizada en: data/dataset_metadata.json\n",
            "Resumen cambios:\n",
            "{'PORCENTAJE (1°)': {'after_nonnull': 203,\n",
            "                     'before_nonnull': 203,\n",
            "                     'clean_column': 'PORCENTAJE (1°)_clean'},\n",
            " 'PORCENTAJE (2°)': {'after_nonnull': 30,\n",
            "                     'before_nonnull': 96,\n",
            "                     'clean_column': 'PORCENTAJE (2°)_clean'},\n",
            " 'PORCENTAJE (3°)': {'after_nonnull': 4,\n",
            "                     'before_nonnull': 90,\n",
            "                     'clean_column': 'PORCENTAJE (3°)_clean'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Features y Preprocesado reproducible\n",
        "\n",
        "## Objetivo:\n",
        "definir y aplicar transformaciones necesarias de forma reproducible y versionable. Cómo usar: ejecutar la celda de definición de funciones y pipeline, luego pipeline, maps = build_preprocessing_pipeline() y df_transformed = apply_transformations(df, pipeline, maps).\n",
        "\n",
        "Transformaciones propuestas y justificación (priorizar variables de alto impacto):\n",
        "\n",
        "## LIMPIEZA:\n",
        "Eliminar columnas vacías y normalizar nombres de columna para evitar errores de parsing en producción.\n",
        "\n",
        "## CODIFICACIÓN ORDINAL de ESTADO → ESTADO_ORD:\n",
        "Mantiene orden implícito de avance (p. ej. Prospección < Exploración < Desarrollo < Producción) y ayuda a modelos lineales/árbol.\n",
        "\n",
        "## AGRUPACIÓN REGIONAL (PROVINCIA → REGION):\n",
        "reduce cardinalidad y captura correlaciones geográficas.\n",
        "\n",
        "## ENCODING MINERAL (MINERAL PRINCIPAL):\n",
        "target/one-hot según modelo; por defecto usamos OneHotEncoder limitado a top-k (resto -> Otros).\n",
        "\n",
        "## LAT/LONG:\n",
        "mantener como numérico y generar columnas de lat-long normalizadas (StandardScaler). Posible derivación: cluster geográfico (KMeans) opcional.\n",
        "\n",
        "## PORCENTAJES:\n",
        "usar columnas ya normalizadas (_clean) y rellenar NaN con 0 si semántica indica ausencia.\n",
        "\n",
        "## FEATURES DERIVADOS:\n",
        "Contar controlantes (si hay múltiples columnas CONTROLANTE n°) -> número de empresas asociadas; texto a bandera (presence/absence).\n",
        "\n",
        "## TIPOS Y CONSISTENCIA:\n",
        "Asegurar tipos numéricos para todas las columnas numéricas y strings para categóricas.\n",
        "\n",
        "## Checks mínimos:\n",
        "No pérdida de filas al aplicar pipeline.\n",
        "Tipos finales correctos.\n",
        "Reutilizabilidad: apply_transformations devuelve df y diccionarios de mapeo/encoders.\n",
        "\n",
        "Artefactos:\n",
        "pipeline.joblib (pipeline completo)\n",
        "encoders.joblib (mapas simples, p. ej. ESTADO map)\n",
        "pipeline_description.md (lista de transformaciones aplicadas y orden)"
      ],
      "metadata": {
        "id": "0LLd_x-6LG1s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helpers y mapeos"
      ],
      "metadata": {
        "id": "m9s3Ki3qUiBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.A Helpers y mapeos mínimos\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "def build_estado_map():\n",
        "    return {\"Prospección\":0,\"Exploración inicial\":1,\"Exploración avanzada\":2,\"Desarrollo\":3,\"Producción\":4}\n",
        "\n",
        "def province_to_region(s):\n",
        "    norte = {\"Salta\",\"Jujuy\",\"Catamarca\",\"Santiago del Estero\",\"Tucumán\",\"La Rioja\"}\n",
        "    centro = {\"Córdoba\",\"San Luis\",\"Santa Fe\",\"Entre Ríos\"}\n",
        "    sur = {\"Río Negro\",\"Neuquén\",\"Chubut\",\"Santa Cruz\",\"Tierra del Fuego\"}\n",
        "    s = pd.Series(s).astype(str).str.strip()\n",
        "    out = s.map(lambda p: \"Desconocido\" if p.lower() in (\"nan\",\"\") else (\"Norte\" if p in norte else \"Centro\" if p in centro else \"Sur\" if p in sur else \"Otra\"))\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "gxvgJce1TktF"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### builder del pipeline"
      ],
      "metadata": {
        "id": "iNNhgQ4MUnCA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.B Pipeline compacto: detecta columnas en df y construye ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "def build_compact_pipeline(df, topk_minerals=8):\n",
        "    numeric = [c for c in df.columns if c in (\"LATITUD\",\"LONGITUD\") or (\"PORCENTAJE\" in c.upper() and \"_clean\" in c)]\n",
        "    # fallback by dtype\n",
        "    if not numeric:\n",
        "        numeric = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]\n",
        "    # top-k minerals\n",
        "    top_m = df.get(\"MINERAL PRINCIPAL\", pd.Series()).fillna(\"Desconocido\").value_counts().index[:topk_minerals].tolist()\n",
        "    # pipelines\n",
        "    num_pipe = Pipeline([(\"imp\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())])\n",
        "    # FIX: Ensure 2D output for 'estado' transformer and impute NaNs\n",
        "    estado_pipe = Pipeline([\n",
        "        (\"map\", FunctionTransformer(lambda x: x.iloc[:, 0].astype(str).map(build_estado_map()).to_frame(), validate=False)),\n",
        "        (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=-1)) # Impute NaNs after mapping\n",
        "    ])\n",
        "    # FIX: Ensure 2D output for 'region' transformer\n",
        "    region_pipe = Pipeline([(\"map\", FunctionTransformer(lambda x: province_to_region(x.iloc[:, 0]).to_frame(), validate=False))])\n",
        "    # FIX: Extract the single column from DataFrame 'x' before processing AND ensure 2D output for OneHotEncoder\n",
        "    mineral_pipe = Pipeline([(\"topk\", FunctionTransformer(lambda x: pd.Series(x.iloc[:, 0]).fillna(\"Desconocido\").astype(str).apply(lambda v: v if v in top_m else \"Otros\").to_frame(), validate=False)),\n",
        "                             (\"ohe\", OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\"))])\n",
        "    ct = ColumnTransformer([\n",
        "        (\"num\", num_pipe, numeric),\n",
        "        (\"estado\", estado_pipe, [\"ESTADO\"]),\n",
        "        (\"region\", region_pipe, [\"PROVINCIA\"]),\n",
        "        (\"mineral\", mineral_pipe, [\"MINERAL PRINCIPAL\"]),\n",
        "    ], remainder=\"passthrough\", verbose_feature_names_out=False)\n",
        "    return Pipeline([(\"preproc\", ct)]), {\"numeric\": numeric, \"top_minerals\": top_m}"
      ],
      "metadata": {
        "id": "cZIzJVY4ToIf"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### fit, transform, reconstrucción mínima y test"
      ],
      "metadata": {
        "id": "hWwQCKMUUuT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.C Fit + transform + reconstrucción mínima + test 3 filas\n",
        "from IPython.display import display\n",
        "import numpy as np, pandas as pd\n",
        "\n",
        "pipeline, maps = build_compact_pipeline(df, topk_minerals=8)\n",
        "fitted = pipeline.fit(df)                # fit sobre el dataset limpio\n",
        "arr = fitted.transform(df)\n",
        "\n",
        "# Reconstrucción mínima: numeric, estado, region, minerals, remainder\n",
        "n_num = len(maps[\"numeric\"])\n",
        "n_min = len(maps[\"top_minerals\"]) + 1   # +1 = \"Otros\" si aparece\n",
        "idx = 0\n",
        "parts = {}\n",
        "if n_num>0:\n",
        "    parts.update({f\"num_{c}\": arr[:, idx+i].astype(float) for i,c in enumerate(maps[\"numeric\"])})\n",
        "    idx += n_num\n",
        "parts[\"ESTADO_ORD\"] = arr[:, idx].astype(float); idx += 1\n",
        "parts[\"REGION\"] = pd.Series(arr[:, idx].astype(object)).replace({np.nan: None}); idx += 1\n",
        "min_cols = [f\"mineral_{m}\" for m in maps[\"top_minerals\"]] + [\"mineral_Otros\"]\n",
        "for i, name in enumerate(min_cols):\n",
        "    parts[name] = arr[:, idx + i].astype(int)\n",
        "idx += n_min\n",
        "# remainder (si existe)\n",
        "if arr.shape[1] > idx:\n",
        "    rem = arr[:, idx:]\n",
        "    # assign generic names for remainder; keep original df columns not used above\n",
        "    used = set(maps[\"numeric\"] + [\"ESTADO\",\"PROVINCIA\",\"MINERAL PRINCIPAL\"])\n",
        "    rem_names = [c for c in df.columns if c not in used]\n",
        "    if rem.shape[1] != len(rem_names):\n",
        "        rem_names = [f\"remainder_{i}\" for i in range(rem.shape[1])]\n",
        "    for i, name in enumerate(rem_names):\n",
        "        parts[name] = rem[:, i]\n",
        "\n",
        "df_trans = pd.DataFrame(parts, index=df.index)\n",
        "# Tests rápidos\n",
        "display(pd.concat([df.head(3).reset_index(drop=True), df_trans.head(3).reset_index(drop=True)], axis=1))\n",
        "print(\"Filas originales:\", len(df), \"| Filas transformadas:\", len(df_trans))\n",
        "print(\"Tipos transformado (ejemplo):\")\n",
        "print(df_trans.dtypes.apply(lambda x: x.name).to_string())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 800
        },
        "id": "gRhFwdb2TsWS",
        "outputId": "9e650887-3384-47ae-9760-7f7938271569"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   N°             NOMBRE  LATITUD  LONGITUD MINERAL PRINCIPAL PROVINCIA  \\\n",
              "0   1  20 de septiembre   -24.896   -68.136            Hierro     Salta   \n",
              "1   2           Acazoque  -24.291   -66.378             Plomo     Salta   \n",
              "2   3   Acoite/Hornillos  -22.305   -65.107             Plomo     Salta   \n",
              "\n",
              "                ESTADO        CONTROLANTE (1°) PORCENTAJE (1°)  ORIGEN (1°)  \\\n",
              "0  Exploración inicial        Diego Ruben Omar             NaN          NaN   \n",
              "1  Exploración inicial             Nuñez Ramon             NaN          NaN   \n",
              "2  Exploración inicial  Rubiolo Daniel Gerardo             NaN          NaN   \n",
              "\n",
              "   ...        CONTROLANTE (1°) PORCENTAJE (1°)  ORIGEN (1°) CONTROLANTE (2°)  \\\n",
              "0  ...        Diego Ruben Omar             NaN          NaN              NaN   \n",
              "1  ...             Nuñez Ramon             NaN          NaN              NaN   \n",
              "2  ...  Rubiolo Daniel Gerardo             NaN          NaN              NaN   \n",
              "\n",
              "   ORIGEN (2°) PORCENTAJE (2°) CONTROLANTE (3°)  PORCENTAJE (3°)  ORIGEN (3°)  \\\n",
              "0          NaN             NaN              NaN              NaN          NaN   \n",
              "1          NaN             NaN              NaN              NaN          NaN   \n",
              "2          NaN             NaN              NaN              NaN          NaN   \n",
              "\n",
              "   Unnamed: 16  \n",
              "0          NaN  \n",
              "1          NaN  \n",
              "2          NaN  \n",
              "\n",
              "[3 rows x 48 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d2eb2fb2-d21c-45ba-bab6-3d6ef236d785\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>N°</th>\n",
              "      <th>NOMBRE</th>\n",
              "      <th>LATITUD</th>\n",
              "      <th>LONGITUD</th>\n",
              "      <th>MINERAL PRINCIPAL</th>\n",
              "      <th>PROVINCIA</th>\n",
              "      <th>ESTADO</th>\n",
              "      <th>CONTROLANTE (1°)</th>\n",
              "      <th>PORCENTAJE (1°)</th>\n",
              "      <th>ORIGEN (1°)</th>\n",
              "      <th>...</th>\n",
              "      <th>CONTROLANTE (1°)</th>\n",
              "      <th>PORCENTAJE (1°)</th>\n",
              "      <th>ORIGEN (1°)</th>\n",
              "      <th>CONTROLANTE (2°)</th>\n",
              "      <th>ORIGEN (2°)</th>\n",
              "      <th>PORCENTAJE (2°)</th>\n",
              "      <th>CONTROLANTE (3°)</th>\n",
              "      <th>PORCENTAJE (3°)</th>\n",
              "      <th>ORIGEN (3°)</th>\n",
              "      <th>Unnamed: 16</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>20 de septiembre</td>\n",
              "      <td>-24.896</td>\n",
              "      <td>-68.136</td>\n",
              "      <td>Hierro</td>\n",
              "      <td>Salta</td>\n",
              "      <td>Exploración inicial</td>\n",
              "      <td>Diego Ruben Omar</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>Diego Ruben Omar</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Acazoque</td>\n",
              "      <td>-24.291</td>\n",
              "      <td>-66.378</td>\n",
              "      <td>Plomo</td>\n",
              "      <td>Salta</td>\n",
              "      <td>Exploración inicial</td>\n",
              "      <td>Nuñez Ramon</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>Nuñez Ramon</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Acoite/Hornillos</td>\n",
              "      <td>-22.305</td>\n",
              "      <td>-65.107</td>\n",
              "      <td>Plomo</td>\n",
              "      <td>Salta</td>\n",
              "      <td>Exploración inicial</td>\n",
              "      <td>Rubiolo Daniel Gerardo</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>Rubiolo Daniel Gerardo</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 48 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d2eb2fb2-d21c-45ba-bab6-3d6ef236d785')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d2eb2fb2-d21c-45ba-bab6-3d6ef236d785 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d2eb2fb2-d21c-45ba-bab6-3d6ef236d785');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7fe9326d-aae4-4edf-a22f-9fa45004b92f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7fe9326d-aae4-4edf-a22f-9fa45004b92f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7fe9326d-aae4-4edf-a22f-9fa45004b92f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filas originales: 325 | Filas transformadas: 325\n",
            "Tipos transformado (ejemplo):\n",
            "num_LATITUD                  float64\n",
            "num_LONGITUD                 float64\n",
            "num_PORCENTAJE (1°)_clean    float64\n",
            "num_PORCENTAJE (2°)_clean    float64\n",
            "num_PORCENTAJE (3°)_clean    float64\n",
            "ESTADO_ORD                   float64\n",
            "REGION                        object\n",
            "mineral_Cobre                  int64\n",
            "mineral_Litio                  int64\n",
            "mineral_Oro                    int64\n",
            "mineral_Plata                  int64\n",
            "mineral_Plomo                  int64\n",
            "mineral_Uranio                 int64\n",
            "mineral_Hierro                 int64\n",
            "mineral_Manganeso              int64\n",
            "mineral_Otros                  int64\n",
            "N°                            object\n",
            "NOMBRE                        object\n",
            "CONTROLANTE (1°)              object\n",
            "PORCENTAJE (1°)               object\n",
            "ORIGEN (1°)                   object\n",
            "CONTROLANTE (2°)              object\n",
            "ORIGEN (2°)                   object\n",
            "PORCENTAJE (2°)               object\n",
            "CONTROLANTE (3°)              object\n",
            "PORCENTAJE (3°)               object\n",
            "ORIGEN (3°)                   object\n",
            "Unnamed: 16                   object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce3c3c5f",
        "outputId": "3c2c399f-aa55-4b2f-dc72-a00ed88f4adc"
      },
      "source": [
        "# 4.D Revisar y coercionar columnas 'object' restantes en df_trans\n",
        "\n",
        "print(\"--- Columnas con dtype 'object' en df_trans y muestra de valores ---\")\n",
        "\n",
        "object_cols_in_trans = df_trans.select_dtypes(include='object').columns\n",
        "\n",
        "if len(object_cols_in_trans) == 0:\n",
        "    print(\"¡No hay columnas con dtype 'object' en df_trans! Ya está todo numérico o ya fue procesado.\")\n",
        "else:\n",
        "    for col in object_cols_in_trans:\n",
        "        print(f\"\\nColumna: '{col}' (dtype: {df_trans[col].dtype})\")\n",
        "        unique_vals = df_trans[col].dropna().unique()\n",
        "\n",
        "        if len(unique_vals) < 50: # Mostrar todos los únicos si son pocos\n",
        "            print(\"Valores únicos (muestra pequeña):\", unique_vals)\n",
        "        else: # Mostrar una muestra aleatoria si hay muchos\n",
        "            print(f\"Total de valores únicos: {len(unique_vals)}. Muestra aleatoria:\")\n",
        "            print(np.random.choice(unique_vals, 20, replace=False))\n",
        "\n",
        "        # Intentar inferir si podría ser numérico\n",
        "        numeric_like_count = df_trans[col].astype(str).str.contains(r'[0-9]', na=False).sum()\n",
        "        if numeric_like_count > 0 and numeric_like_count < len(df_trans[col].dropna()):\n",
        "            print(f\"  -> Contiene {numeric_like_count} valores que parecen numéricos/mixtos (de {len(df_trans[col].dropna())} no nulos).\")\n",
        "        elif numeric_like_count == len(df_trans[col].dropna()) and len(df_trans[col].dropna()) > 0:\n",
        "            print(f\"  -> Todos los {len(df_trans[col].dropna())} valores no nulos parecen numéricos.\")\n",
        "        else:\n",
        "            print(\"  -> No contiene valores que parezcan numéricos en los no nulos.\")\n",
        "\n",
        "print(\"\\n--- Análisis de columnas completado. ---\")\n",
        "print(\"Basado en esta revisión, se pueden identificar las columnas 'object' que deban ser convertidas a numéricas.\")\n"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Columnas con dtype 'object' en df_trans y muestra de valores ---\n",
            "\n",
            "Columna: 'REGION' (dtype: object)\n",
            "Valores únicos (muestra pequeña): ['Norte' 'Sur' 'Otra']\n",
            "  -> No contiene valores que parezcan numéricos en los no nulos.\n",
            "\n",
            "Columna: 'N°' (dtype: object)\n",
            "Total de valores únicos: 325. Muestra aleatoria:\n",
            "[235 111 249 10 94 220 288 199 204 102 182 256 318 140 321 154 147 145 26\n",
            " 6]\n",
            "  -> Todos los 325 valores no nulos parecen numéricos.\n",
            "\n",
            "Columna: 'NOMBRE' (dtype: object)\n",
            "Total de valores únicos: 314. Muestra aleatoria:\n",
            "['El Bagual' 'Minas Futuro' 'San José' 'Punilla' 'Córdoba' 'El Peñon'\n",
            " 'Los Azules' 'Hope' 'Puna Operation (Chinchillas - Pirquitas)'\n",
            " 'Sor Rafaela' 'Vista Alegre' 'Taca Sal IV' 'Organullo' 'Don Otto'\n",
            " 'Tanque Negro' 'Pozuelos (PPG)' 'Claudia' 'La Niquelina' 'Co. La Mina'\n",
            " 'Alfil']\n",
            "  -> Contiene 3 valores que parecen numéricos/mixtos (de 325 no nulos).\n",
            "\n",
            "Columna: 'CONTROLANTE (1°)' (dtype: object)\n",
            "Total de valores únicos: 144. Muestra aleatoria:\n",
            "['Antofalla Minerals S.A (Marcelo López Acuña)' 'Orosur Mining Inc.'\n",
            " 'MOM Mining SRL' 'Hochschild Mining Plc' 'Revotech Asia Ltda. '\n",
            " 'South32 ltd.' 'Cosmos Minerals S.A.' 'Latin Metals Inc.'\n",
            " 'Zijin Mining Group Ltd.' 'Astra Exploration ' 'Pan American Energy'\n",
            " 'Espíritu de los Andes S.A.' 'Aldebaran Resources Inc.'\n",
            " 'Fredonia Mining Inc.' 'Albemarle Corporation' 'Minera Santa Rita S.R.L.'\n",
            " 'Chengxin Lithium Group. Co.' 'MIM Argentina Exploraciones S.A'\n",
            " 'Lithium Energi Exploration Inc' 'Aguilar Polimetalica']\n",
            "  -> Contiene 2 valores que parecen numéricos/mixtos (de 228 no nulos).\n",
            "\n",
            "Columna: 'PORCENTAJE (1°)' (dtype: object)\n",
            "Valores únicos (muestra pequeña): [1.0 0.8 0.65 0.95 0.467 0.925 0.5 0.75 0.9 0.47 0.67 0.85 0.7 0.46 0.51\n",
            " 0.6 0.501]\n",
            "  -> Todos los 203 valores no nulos parecen numéricos.\n",
            "\n",
            "Columna: 'ORIGEN (1°)' (dtype: object)\n",
            "Valores únicos (muestra pequeña): ['Argentina' 'Canadá' 'Argentina ' 'China' 'Australia' 'Canadá '\n",
            " 'Estados Unidos ' 'Reino Unido' 'Francia' 'Estados Unidos' 'Sudáfrica'\n",
            " 'Suiza' 'Australia ' 'Corea del Sur' 'Paises Bajos ' 'China ']\n",
            "  -> No contiene valores que parezcan numéricos en los no nulos.\n",
            "\n",
            "Columna: 'CONTROLANTE (2°)' (dtype: object)\n",
            "Valores únicos (muestra pequeña): ['Sibanye Stillwater' '-' 'SMG S.R.L.' 'NewPeak Metals Limited' 'Fomicruz'\n",
            " 'Lithium Argentina' 'AbraSilver Corp.' 'Sable Resources Ltd.'\n",
            " 'Deseado Dorado S. A. S.' 'BHP Group Corp.' 'BHP Group '\n",
            " 'Lilac Solutions Inc.' 'Shandong Gold Mining' 'Stellantis'\n",
            " 'Toyota Tsusho' 'Latin Metals Inc.' 'Ganfeng Lithium'\n",
            " 'Compañía Minera Piuquenes S.A.' 'Regberg Ltd.'\n",
            " 'Tibet Summit Resources Co., Ltd' 'Grupo Alberdi' 'McEwen Mining Inc.'\n",
            " 's/n' 'CAM' 'Minsud Resources Corp.' 'Shandong Gold Mining Co. Ltd.']\n",
            "  -> No contiene valores que parezcan numéricos en los no nulos.\n",
            "\n",
            "Columna: 'ORIGEN (2°)' (dtype: object)\n",
            "Valores únicos (muestra pequeña): ['Sudáfrica' '-' 'Argentina' 'Australia' 'Canadá' 'Estados Unidos' 'China'\n",
            " 'Países Bajos' 'Japón' 49.9]\n",
            "  -> Contiene 1 valores que parecen numéricos/mixtos (de 92 no nulos).\n",
            "\n",
            "Columna: 'PORCENTAJE (2°)' (dtype: object)\n",
            "Valores únicos (muestra pequeña): [0.2 0.35 0.05 0.448 0.075 0.5 0.25 0.1 0.19 0.15 0.3 0.45 0.49 0.4]\n",
            "  -> Todos los 30 valores no nulos parecen numéricos.\n",
            "\n",
            "Columna: 'CONTROLANTE (3°)' (dtype: object)\n",
            "Valores únicos (muestra pequeña): ['-' 'Jujuy Energia y Mineria' 'Otros' 'Jujuy Energía y Minería'\n",
            " 'Leading Resources Global Ltd.']\n",
            "  -> No contiene valores que parezcan numéricos en los no nulos.\n",
            "\n",
            "Columna: 'PORCENTAJE (3°)' (dtype: object)\n",
            "Valores únicos (muestra pequeña): [0.085 0.33 0.09]\n",
            "  -> Todos los 4 valores no nulos parecen numéricos.\n",
            "\n",
            "Columna: 'ORIGEN (3°)' (dtype: object)\n",
            "Valores únicos (muestra pequeña): ['-' 'Argentina' 'Reino Unido']\n",
            "  -> No contiene valores que parezcan numéricos en los no nulos.\n",
            "\n",
            "Columna: 'Unnamed: 16' (dtype: object)\n",
            "Valores únicos (muestra pequeña): ['Bombeo - La salmuera es bombeada desde los acuíferos hacia las piletas de evaporación, la cual luego pasa a un proceso químico en la planta para lograr la concentración adecuada.']\n",
            "  -> No contiene valores que parezcan numéricos en los no nulos.\n",
            "\n",
            "--- Análisis de columnas completado. ---\n",
            "Basado en esta revisión, se pueden identificar las columnas 'object' que deban ser convertidas a numéricas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5caa8531",
        "outputId": "de5ab691-233b-4703-b1c2-03da0bdc4edf"
      },
      "source": [
        "# 4.F Coerción y Eliminación de columnas restantes de tipo 'object'\n",
        "\n",
        "# Convertir 'N°' a int64\n",
        "# Manejar posibles NaN si los hubiera antes de la conversión a int, aunque el análisis mostró 0 nulos.\n",
        "if 'N°' in df_trans.columns:\n",
        "    df_trans['N°'] = pd.to_numeric(df_trans['N°'], errors='coerce').astype('Int64') # Usar Int64 para soportar NaN\n",
        "    print(\"Columna 'N°' convertida a Int64.\")\n",
        "else:\n",
        "    print(\"Columna 'N°' no encontrada en df_trans.\")\n",
        "\n",
        "# Columnas de porcentaje originales a eliminar por redundancia\n",
        "redundant_pct_cols = [c for c in ['PORCENTAJE (1°)', 'PORCENTAJE (2°)', 'PORCENTAJE (3°)'] if c in df_trans.columns]\n",
        "if redundant_pct_cols:\n",
        "    df_trans = df_trans.drop(columns=redundant_pct_cols)\n",
        "    print(f\"Columnas redundantes de porcentaje eliminadas: {redundant_pct_cols}\")\n",
        "else:\n",
        "    print(\"No se encontraron columnas de porcentaje redundantes a eliminar.\")\n",
        "\n",
        "# Eliminar columna 'Unnamed: 16' si existe\n",
        "unnamed_col = 'Unnamed: 16'\n",
        "if unnamed_col in df_trans.columns:\n",
        "    df_trans = df_trans.drop(columns=[unnamed_col])\n",
        "    print(f\"Columna '{unnamed_col}' eliminada.\")\n",
        "else:\n",
        "    print(f\"Columna '{unnamed_col}' no encontrada en df_trans.\")\n",
        "\n",
        "print(\"\\n--- Revisión final de columnas 'object' restantes ---\")\n",
        "object_cols_final = df_trans.select_dtypes(include='object').columns\n",
        "if len(object_cols_final) == 0:\n",
        "    print(\"¡No hay columnas con dtype 'object' en df_trans! Todas han sido procesadas o son numéricas.\")\n",
        "else:\n",
        "    print(\"Columnas 'object' restantes (son features categóricas textuales):\")\n",
        "    for col in object_cols_final:\n",
        "        print(f\"- {col}\")\n",
        "\n",
        "print(\"\\n--- Resumen de df_trans después de las últimas coerciones ---\")\n",
        "print(f\"Filas: {df_trans.shape[0]} | Columnas: {df_trans.shape[1]}\")\n",
        "print(\"Dtypes actualizados (muestra):\")\n",
        "print(df_trans.dtypes.apply(lambda x: x.name).to_string())"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columna 'N°' convertida a Int64.\n",
            "Columnas redundantes de porcentaje eliminadas: ['PORCENTAJE (1°)', 'PORCENTAJE (2°)', 'PORCENTAJE (3°)']\n",
            "Columna 'Unnamed: 16' eliminada.\n",
            "\n",
            "--- Revisión final de columnas 'object' restantes ---\n",
            "Columnas 'object' restantes (son features categóricas textuales):\n",
            "- REGION\n",
            "- NOMBRE\n",
            "- CONTROLANTE (1°)\n",
            "- ORIGEN (1°)\n",
            "- CONTROLANTE (2°)\n",
            "- ORIGEN (2°)\n",
            "- CONTROLANTE (3°)\n",
            "- ORIGEN (3°)\n",
            "\n",
            "--- Resumen de df_trans después de las últimas coerciones ---\n",
            "Filas: 325 | Columnas: 24\n",
            "Dtypes actualizados (muestra):\n",
            "num_LATITUD                  float64\n",
            "num_LONGITUD                 float64\n",
            "num_PORCENTAJE (1°)_clean    float64\n",
            "num_PORCENTAJE (2°)_clean    float64\n",
            "num_PORCENTAJE (3°)_clean    float64\n",
            "ESTADO_ORD                   float64\n",
            "REGION                        object\n",
            "mineral_Cobre                  int64\n",
            "mineral_Litio                  int64\n",
            "mineral_Oro                    int64\n",
            "mineral_Plata                  int64\n",
            "mineral_Plomo                  int64\n",
            "mineral_Uranio                 int64\n",
            "mineral_Hierro                 int64\n",
            "mineral_Manganeso              int64\n",
            "mineral_Otros                  int64\n",
            "N°                             Int64\n",
            "NOMBRE                        object\n",
            "CONTROLANTE (1°)              object\n",
            "ORIGEN (1°)                   object\n",
            "CONTROLANTE (2°)              object\n",
            "ORIGEN (2°)                   object\n",
            "CONTROLANTE (3°)              object\n",
            "ORIGEN (3°)                   object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "935e84c6"
      },
      "source": [
        "## Conclusiones Finales: Features y Preprocesado Reproducible\n",
        "\n",
        "Esta sección ha consolidado y refinado el proceso de preparación de datos, resultando en un dataset `df_trans` completamente preprocesado y listo para la fase de modelado. Los logros clave incluyen:\n",
        "\n",
        "1.  **Limpieza y Normalización Inicial de Datos:**\n",
        "    *   **Columnas de Porcentaje:** Las columnas `PORCENTAJE (1°)`, `PORCENTAJE (2°)` y `PORCENTAJE (3°)` fueron inicialmente limpiadas de caracteres no numéricos y convertidas a tipo `float`. Sus versiones originales (`PORCENTAJE (n°)`) fueron posteriormente eliminadas, dejando solo las versiones limpias y escaladas (`num_PORCENTAJE (n°)_clean`) para evitar redundancia y ambigüedad.\n",
        "    *   **Columnas Residuales:** La columna `Unnamed: 16`, identificada como un residuo con valores vacíos o irrelevantes, fue eliminada para limpiar el dataset.\n",
        "    *   **Coerción de Tipos de Identificadores:** La columna `'N°'`, que representaba un identificador numérico pero estaba como `object`, se convirtió explícitamente a `Int64` para asegurar su correcto tipo y manejo de posibles nulos.\n",
        "\n",
        "2.  **Ingeniería de Features Específica del Dominio:**\n",
        "    *   **Codificación Ordinal de `ESTADO`:** Se creó la columna `ESTADO_ORD` transformando la variable categórica `ESTADO` en una representación numérica ordenada, reflejando la progresión natural de las fases de un proyecto minero (Prospección < Exploración < Desarrollo < Producción). Esto permite a los modelos capturar la ordinalidad inherente.\n",
        "    *   **Agrupación Regional (`REGION`):** A partir de la columna `PROVINCIA`, se derivó una nueva característica `REGION` (Norte, Centro, Sur, Otra, Desconocido). Esto reduce la cardinalidad de la variable geográfica, agrupa provincias con características similares y ayuda a capturar patrones regionales más generales.\n",
        "    *   **Codificación de `MINERAL PRINCIPAL`:** Esta variable categórica se procesó mediante un esquema de 'one-hot encoding' (`mineral_Cobre`, `mineral_Litio`, etc.). Se utilizó una estrategia de `top-k` (los 8 minerales más frecuentes) y el resto se agrupó en una categoría 'Otros', evitando la explosión de dimensionalidad y permitiendo a los modelos interpretar la presencia de tipos de mineral.\n",
        "\n",
        "3.  **Estandarización de Features Numéricas:**\n",
        "    *   Las columnas numéricas como `LATITUD`, `LONGITUD` y los `PORCENTAJES` limpios (`num_PORCENTAJE (n°)_clean`) fueron imputadas (con la mediana para manejar nulos) y escaladas utilizando `StandardScaler`. Esto asegura que todas las características numéricas tengan una media de cero y una varianza unitaria, lo que es crucial para el buen desempeño de muchos algoritmos de aprendizaje automático.\n",
        "\n",
        "4.  **Pipeline Compacto y Robusto (`scikit-learn`):**\n",
        "    *   Se construyó y ajustó un `Pipeline` con `ColumnTransformer` que encapsula todas las transformaciones anteriores de manera modular y reproducible. Este diseño permite aplicar consistentemente el mismo conjunto de pasos a cualquier nuevo dato y es fundamental para la validación cruzada y la inferencia en producción.\n",
        "    *   Se resolvieron errores clave como `AttributeError: 'DataFrame' object has no attribute 'ravel'` y `ValueError` relacionados con la forma de las entradas a los transformadores, así como `PicklingError` y `TypeError` asociados a la serialización de componentes personalizados (`lambda` y clases anidadas), haciendo el pipeline robusto y serializable.\n",
        "\n",
        "5.  **Reconstrucción y Verificación del `DataFrame` Final:**\n",
        "    *   La salida del `ColumnTransformer` (un array NumPy) fue meticulosamente reconstruida en un `DataFrame` (`df_trans`) con nombres de columna legibles (`num_LATITUD`, `ESTADO_ORD`, `REGION`, `mineral_Cobre`, etc.) y tipos de datos correctos. Esta reconstrucción es vital para la interpretabilidad y para asegurar que el `DataFrame` esté listo para las siguientes fases.\n",
        "\n",
        "6.  **Persistencia de Artefactos:** El `fitted_pipeline` (pipeline ajustado) y `maps` (diccionarios de mapeo para estados, top-k minerales) se han guardado con `joblib` y `json` en `data/artifacts`. Esto garantiza la reproducibilidad completa del preprocesamiento, permitiendo recargar el modelo y aplicar las mismas transformaciones sin necesidad de reentrenar o recalcular los mapeos.\n",
        "\n",
        "El `df_trans` final, con **325 filas y 24 columnas**, es un conjunto de datos estandarizado, limpio, con las características diseñadas, y con los tipos de datos correctos, listo para alimentar los modelos de clasificación y abordar el objetivo de predecir la etapa avanzada de los proyectos mineros."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Estrategia de split y validación reproducible\n",
        "\n",
        "## Objetivo\n",
        "Definir y persistir un split reproducible (train / val / test) y, opcionalmente, folds de CV estratificados. Justificación: reservar un test final fijo (10–20%) para estimación no sesgada del rendimiento; usar validación cruzada estratificada en el entrenamiento para selección de modelos cuando hay clase desbalanceada o variables categóricas con distinta prevalencia. Guardamos índices y un resumen para auditoría y reproducción exacta.\n",
        "\n",
        "## Decisiones prácticas que tomamos para este analisis\n",
        "\n",
        "Test final: 15% por defecto (ajustable).\n",
        "\n",
        "Val: 15% (o usar CV dentro del train si prefieres k-fold).\n",
        "\n",
        "Estratificar por la variable target si es categórica; si no existe una columna target obvia, el código intenta inferir varias opciones razonables y falla con mensaje claro.\n",
        "\n",
        "Semilla fija (RANDOM_STATE) para reproducibilidad.\n",
        "\n",
        "Guardar índices en joblib y un CSV resumen con distribuciones por split."
      ],
      "metadata": {
        "id": "uTYT9EaFZnl2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Estrategia elegida: train / val / test con test final retenido para evaluación definitiva.\n",
        "#### Proporciones por defecto: train 70%, val 15%, test 15% (modificable).\n",
        "#### Estratificación: se aplica si la variable target es categórica; si no, se realiza un split aleatorio mantenido por semilla.\n",
        "#### Reproducibilidad: indices guardados en joblib; resume de distribuciones guardado en split_summary.csv.\n",
        "\n",
        "\n",
        "**Uso: ejecutar la celda de código siguiente para crear splits; luego usar indices guardados para entrenar/evaluar modelos sin re-samplear.**\n"
      ],
      "metadata": {
        "id": "10dnNWLQZ6X0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5.1 Crear splits reproducibles (train/val/test) y guardar índices\n",
        "import os, joblib, json\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "DATA_DIR = Path(\"data\")\n",
        "ART = DATA_DIR / \"artifacts\"\n",
        "ART.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "TEST_SIZE = 0.15   # ajustar si preferís 0.1 o 0.2\n",
        "VAL_SIZE = 0.15\n",
        "\n",
        "# Intentar inferir la columna target en el DF 'df'\n",
        "candidate_targets = [\"TARGET\",\"target\",\"etapa_avanzada\",\"ETAPA_AVANZADA\",\"ETAPA\",\"CLASE\",\"label\",\"y\",\"Y\",\"ESTADO\"]\n",
        "target_col = None\n",
        "for c in candidate_targets:\n",
        "    if c in df.columns:\n",
        "        target_col = c\n",
        "        break\n",
        "if target_col is None:\n",
        "    # buscar columnas binarias o con pocos valores que no sean índice/ID\n",
        "    for c in df.columns:\n",
        "        nunique = df[c].nunique(dropna=True)\n",
        "        if 2 <= nunique <= 20 and not c.lower().startswith(\"num_\") and not c.lower().startswith(\"lat\"):\n",
        "            target_col = c\n",
        "            break\n",
        "if target_col is None:\n",
        "    raise RuntimeError(\"No se encontró una columna target clara. Declarar 'target_col' manualmente o renombrar la columna objetivo.\")\n",
        "\n",
        "print(\"Target seleccionado para splits:\", target_col)\n",
        "\n",
        "# asegurar no usar filas con NA en target\n",
        "mask_valid = ~df[target_col].isna()\n",
        "if mask_valid.sum() != len(df):\n",
        "    print(f\"Aviso: se excluyen {len(df)-mask_valid.sum()} filas con target NA del split.\")\n",
        "df_split = df[mask_valid].reset_index(drop=True)\n",
        "\n",
        "# Verificar si la estratificación es posible para el target seleccionado\n",
        "class_counts = df_split[target_col].value_counts()\n",
        "min_class_count = class_counts.min()\n",
        "\n",
        "is_stratify_overall = False\n",
        "if not pd.api.types.is_numeric_dtype(df_split[target_col]) and df_split[target_col].nunique() < 20:\n",
        "    if min_class_count >= 2:\n",
        "        is_stratify_overall = True\n",
        "    else:\n",
        "        print(f\"Advertencia: No es posible estratificar por '{target_col}' en el split principal porque al menos una clase tiene solo {min_class_count} miembro(s).\")\n",
        "        print(\"Conteo de clases en el target:\", class_counts.to_string())\n",
        "\n",
        "# Primer split: train+val vs test\n",
        "if is_stratify_overall:\n",
        "    trainval_idx, test_idx = train_test_split(df_split.index.to_numpy(), test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=df_split[target_col])\n",
        "else:\n",
        "    trainval_idx, test_idx = train_test_split(df_split.index.to_numpy(), test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
        "\n",
        "# Segundo split: train vs val desde trainval (proporción relativa)\n",
        "rel_val_size = VAL_SIZE / (1.0 - TEST_SIZE)  # fracción de trainval que irá a val\n",
        "\n",
        "is_stratify_trainval = False\n",
        "if is_stratify_overall: # Solo intentamos estratificar train/val si el split general fue estratificable\n",
        "    trainval_class_counts = df_split.loc[trainval_idx, target_col].value_counts()\n",
        "    if trainval_class_counts.min() >= 2:\n",
        "        is_stratify_trainval = True\n",
        "    else:\n",
        "        print(f\"Advertencia: No es posible estratificar por '{target_col}' en el split train/val porque al menos una clase tiene muy pocos miembros en el conjunto trainval.\")\n",
        "        print(\"Conteo de clases en el target para trainval:\", trainval_class_counts.to_string())\n",
        "\n",
        "if is_stratify_trainval:\n",
        "    train_idx, val_idx = train_test_split(trainval_idx, test_size=rel_val_size, random_state=RANDOM_STATE, stratify=df_split.loc[trainval_idx, target_col])\n",
        "else:\n",
        "    train_idx, val_idx = train_test_split(trainval_idx, test_size=rel_val_size, random_state=RANDOM_STATE)\n",
        "\n",
        "# Guardar índices (son índices relativos a df_split)\n",
        "indices_out = {\n",
        "    \"train_idx\": train_idx.tolist(),\n",
        "    \"val_idx\": val_idx.tolist(),\n",
        "    \"test_idx\": test_idx.tolist(),\n",
        "    \"target_col\": target_col,\n",
        "    \"random_state\": RANDOM_STATE,\n",
        "    \"test_size\": TEST_SIZE,\n",
        "    \"val_size\": VAL_SIZE,\n",
        "    \"is_stratified_overall\": is_stratify_overall,\n",
        "    \"is_stratified_trainval\": is_stratify_trainval\n",
        "}\n",
        "joblib.dump(indices_out, ART / \"indices_train_val_test.joblib\")\n",
        "\n",
        "# Crear resumen de distribuciones por split y guardarlo\n",
        "def summarize_split(idxs, name):\n",
        "    sub = df_split.loc[idxs]\n",
        "    d = {\"n_rows\": len(sub)}\n",
        "    # si categórica, mostrar counts por category; si numérica, mostrar quantiles\n",
        "    if not pd.api.types.is_numeric_dtype(sub[target_col]) or sub[target_col].nunique() < 20:\n",
        "        d[\"value_counts\"] = sub[target_col].value_counts(dropna=False).to_dict()\n",
        "    else:\n",
        "        d[\"quantiles\"] = sub[target_col].quantile([0,0.25,0.5,0.75,1.0]).to_dict()\n",
        "    return d\n",
        "\n",
        "summary = {\n",
        "    \"train\": summarize_split(train_idx, \"train\"),\n",
        "    \"val\": summarize_split(val_idx, \"val\"),\n",
        "    \"test\": summarize_split(test_idx, \"test\"),\n",
        "    \"total_rows_available\": int(len(df_split))\n",
        "}\n",
        "# guardar resumen csv y json\n",
        "pd.DataFrame({\n",
        "    \"split\":[\"train\",\"val\",\"test\"],\n",
        "    \"n_rows\":[len(train_idx), len(val_idx), len(test_idx)]\n",
        "}).to_csv(ART / \"split_counts.csv\", index=False)\n",
        "(ART / \"split_summary.json\").write_text(json.dumps(summary, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "\n",
        "print(\"Splits creados y guardados en:\", ART)\n",
        "print(\"Counts -> train:\", len(train_idx), \"val:\", len(val_idx), \"test:\", len(test_idx))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzAjulc1aRPj",
        "outputId": "227a1999-aca6-457e-ca4a-cb33e896ae41"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target seleccionado para splits: ESTADO\n",
            "Advertencia: No es posible estratificar por 'ESTADO' en el split principal porque al menos una clase tiene solo 1 miembro(s).\n",
            "Conteo de clases en el target: ESTADO\n",
            "Exploración inicial                128\n",
            "Exploración avanzada                72\n",
            "Prospección                         61\n",
            "Producción                          26\n",
            "Evaluación Económica Preliminar     11\n",
            "Factibilidad                        10\n",
            "Prefactibilidad                      7\n",
            "Construcción                         7\n",
            "Reingeniería                         2\n",
            "Cese de operaciones                  1\n",
            "Splits creados y guardados en: data/artifacts\n",
            "Counts -> train: 227 val: 49 test: 49\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "661a17b5"
      },
      "source": [
        "## La fase de split de datos se ha completado exitosamente, estableciendo conjuntos reproducibles de entrenamiento, validación y prueba para el desarrollo y evaluación del modelo.\n",
        "\n",
        "### Estrategia y Ejecución:\n",
        "1.  **Objetivo:** El objetivo principal fue crear un split reproducible de los datos, reservando un conjunto de prueba final para la evaluación no sesgada del rendimiento del modelo, y conjuntos de entrenamiento y validación para el desarrollo del modelo.\n",
        "2.  **Variable Target:** Se identificó la columna `'ESTADO'` como la variable objetivo principal para el split.\n",
        "3.  **Manejo de Stratificación:**\n",
        "    *   Se intentó realizar una estratificación por la columna `ESTADO` para asegurar una distribución similar de las clases en cada subconjunto (entrenamiento, validación, prueba).\n",
        "    *   Sin embargo, se detectó que al menos una clase (`'Cese de operaciones'`) tenía solo 1 miembro, lo cual es insuficiente para la estratificación (se necesitan al menos 2 miembros por clase para dividir). En estos casos, se procedió con un split aleatorio para ese paso, evitando un error y garantizando la continuidad del proceso.\n",
        "4.  **Proporciones del Split:** Se utilizaron las proporciones definidas de `15%` para el conjunto de prueba (`test`) y `15%` para el conjunto de validación (`val`) (relativo al resto de los datos), con el resto asignado al conjunto de entrenamiento (`train`).\n",
        "\n",
        "### Resultados Finales:\n",
        "*   **Conjunto de Entrenamiento (train):** 227 filas.\n",
        "*   **Conjunto de Validación (val):** 49 filas.\n",
        "*   **Conjunto de Prueba (test):** 49 filas.\n",
        "\n",
        "### Reproducibilidad:\n",
        "Los índices de cada subconjunto (`train_idx`, `val_idx`, `test_idx`) junto con la configuración del split (`target_col`, `random_state`, `test_size`, `val_size` y la información de si se estratificó o no) han sido guardados en `data/artifacts/indices_train_val_test.joblib`. Además, se generaron archivos `split_counts.csv` y `split_summary.json` para auditar las distribuciones y tamaños de cada split.\n",
        "\n",
        "Con estos conjuntos de datos definidos de manera reproducible, se puede proceder con confianza a la fase de modelado, sabiendo que la evaluación final se realizará sobre un conjunto de datos virgen (`test_idx`)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K-fold estratificado sobre train para CV y guardar folds"
      ],
      "metadata": {
        "id": "NMC3IqGxcG6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5.2 Generar StratifiedKFold sobre el conjunto de train (si aplica) y guardar folds\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import joblib\n",
        "\n",
        "# cargar índices previos\n",
        "meta = joblib.load(ART / \"indices_train_val_test.joblib\")\n",
        "train_idx = np.array(meta[\"train_idx\"])\n",
        "target_col = meta[\"target_col\"]\n",
        "\n",
        "# crear folds solo si target categórico o con pocos valores\n",
        "n_splits = 5\n",
        "if not pd.api.types.is_numeric_dtype(df_split[target_col]) or df_split[target_col].nunique() < 20:\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_STATE)\n",
        "    folds = []\n",
        "    for train_i, val_i in skf.split(train_idx, df_split.loc[train_idx, target_col]):\n",
        "        folds.append({\"train_idx\": train_idx[train_i].tolist(), \"val_idx\": train_idx[val_i].tolist()})\n",
        "    joblib.dump(folds, ART / \"stratified_folds_train.joblib\")\n",
        "    print(f\"{len(folds)} folds estratificados guardados en:\", ART / \"stratified_folds_train.joblib\")\n",
        "else:\n",
        "    print(\"No se generan folds estratificados porque target es numérico con alta cardinalidad.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iy9nSUYWbHrK",
        "outputId": "82271578-cf79-42b5-f8a0-4f5f1fa26756"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 folds estratificados guardados en: data/artifacts/stratified_folds_train.joblib\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checks rápidos de integridad y leakage básicos"
      ],
      "metadata": {
        "id": "pr8b3ng6bN4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5.3 Checks: distribución del target en cada split y verificación simple de leakage\n",
        "import pandas as pd, joblib, numpy as np\n",
        "meta = joblib.load(ART / \"indices_train_val_test.joblib\")\n",
        "train_idx = np.array(meta[\"train_idx\"]); val_idx = np.array(meta[\"val_idx\"]); test_idx = np.array(meta[\"test_idx\"])\n",
        "target_col = meta[\"target_col\"]\n",
        "\n",
        "def show_dist(idxs, name):\n",
        "    sub = df_split.loc[idxs]\n",
        "    print(f\"\\n-- {name} -- n={len(sub)}\")\n",
        "    if not pd.api.types.is_numeric_dtype(sub[target_col]) or sub[target_col].nunique() < 20:\n",
        "        print(sub[target_col].value_counts(dropna=False))\n",
        "    else:\n",
        "        print(sub[target_col].describe())\n",
        "\n",
        "show_dist(train_idx, \"TRAIN\")\n",
        "show_dist(val_idx, \"VAL\")\n",
        "show_dist(test_idx, \"TEST\")\n",
        "\n",
        "# Simple leakage check: columnas que were engineered using full dataset? (sanity)\n",
        "# Aquí comprobamos si alguna columna de features tiene exactamente la misma distribución en train/test (indicio leve)\n",
        "common_cols = [c for c in df.columns if df[c].dtype != 'O' and c not in [target_col]]\n",
        "leak_suspects = []\n",
        "for c in common_cols:\n",
        "    # comparar means\n",
        "    m_train = df_split.loc[train_idx, c].mean()\n",
        "    m_test = df_split.loc[test_idx, c].mean()\n",
        "    if pd.isna(m_train) or pd.isna(m_test): continue\n",
        "    if abs(m_train - m_test) / (abs(m_train) + 1e-9) < 1e-6:  # prácticamente idéntico (muy raro)\n",
        "        leak_suspects.append(c)\n",
        "print(\"\\nVariables con media prácticamente idéntica en train/test (posible leak):\", leak_suspects if leak_suspects else \"ninguna detectada\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C56U5BGybTrV",
        "outputId": "3a20839a-da3a-4c9f-d741-b9739e8d5655"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-- TRAIN -- n=227\n",
            "ESTADO\n",
            "Exploración inicial                87\n",
            "Exploración avanzada               50\n",
            "Prospección                        45\n",
            "Producción                         18\n",
            "Evaluación Económica Preliminar     6\n",
            "Factibilidad                        6\n",
            "Prefactibilidad                     6\n",
            "Construcción                        6\n",
            "Reingeniería                        2\n",
            "Cese de operaciones                 1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "-- VAL -- n=49\n",
            "ESTADO\n",
            "Exploración inicial                23\n",
            "Exploración avanzada               12\n",
            "Prospección                         5\n",
            "Evaluación Económica Preliminar     3\n",
            "Producción                          2\n",
            "Factibilidad                        2\n",
            "Construcción                        1\n",
            "Prefactibilidad                     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "-- TEST -- n=49\n",
            "ESTADO\n",
            "Exploración inicial                18\n",
            "Prospección                        11\n",
            "Exploración avanzada               10\n",
            "Producción                          6\n",
            "Evaluación Económica Preliminar     2\n",
            "Factibilidad                        2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Variables con media prácticamente idéntica en train/test (posible leak): ninguna detectada\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Confirmando archivos generados"
      ],
      "metadata": {
        "id": "uS_9tHFyceye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "p=Path(\"data/artifacts\")\n",
        "print((p/\"indices_train_val_test.joblib\").exists(), (p/\"split_counts.csv\").exists(), (p/\"split_summary.json\").exists())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hY6QH7dncieQ",
        "outputId": "10f5842b-49f1-4841-ef58-7ae04ff7965e"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True True True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validando conservación y estratificación"
      ],
      "metadata": {
        "id": "X6s28bt0clgU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib, numpy as np\n",
        "meta = joblib.load(\"data/artifacts/indices_train_val_test.joblib\")\n",
        "# Se usan las claves correctas: is_stratified_overall y is_stratified_trainval\n",
        "print(\"target_col:\", meta[\"target_col\"], \"is_stratified_overall:\", meta[\"is_stratified_overall\"], \"is_stratified_trainval:\", meta[\"is_stratified_trainval\"])\n",
        "print(\"counts ->\", len(meta[\"train_idx\"]), len(meta[\"val_idx\"]), len(meta[\"test_idx\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYz4K-ljctxu",
        "outputId": "dc492608-2b3b-480d-c0c2-b10f108a93dd"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target_col: ESTADO is_stratified_overall: False is_stratified_trainval: False\n",
            "counts -> 227 49 49\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Distribuciones por split"
      ],
      "metadata": {
        "id": "p9SOQGQOdE1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib, pandas as pd, numpy as np\n",
        "meta = joblib.load(\"data/artifacts/indices_train_val_test.joblib\")\n",
        "df_split = df[~df[meta[\"target_col\"]].isna()].reset_index(drop=True)\n",
        "for name, idxs in [(\"train\", meta[\"train_idx\"]),(\"val\", meta[\"val_idx\"]),(\"test\", meta[\"test_idx\"])]:\n",
        "    s = df_split.loc[idxs, meta[\"target_col\"]]\n",
        "    print(name, \"->\", s.value_counts(dropna=False).to_dict() if not pd.api.types.is_numeric_dtype(s) else s.describe().to_dict())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRV4EiTkdJaJ",
        "outputId": "8a016be0-98f7-464c-9940-c677e1cf976d"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train -> {'Exploración inicial': 87, 'Exploración avanzada': 50, 'Prospección': 45, 'Producción': 18, 'Evaluación Económica Preliminar': 6, 'Factibilidad': 6, 'Prefactibilidad': 6, 'Construcción': 6, 'Reingeniería': 2, 'Cese de operaciones': 1}\n",
            "val -> {'Exploración inicial': 23, 'Exploración avanzada': 12, 'Prospección': 5, 'Evaluación Económica Preliminar': 3, 'Producción': 2, 'Factibilidad': 2, 'Construcción': 1, 'Prefactibilidad': 1}\n",
            "test -> {'Exploración inicial': 18, 'Prospección': 11, 'Exploración avanzada': 10, 'Producción': 6, 'Evaluación Económica Preliminar': 2, 'Factibilidad': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f75d36c2"
      },
      "source": [
        "### Conclusiones de los Checks Rápidos de Integridad y Detección de Leakage\n",
        "\n",
        "1.  **Distribución del Target (`ESTADO`):**\n",
        "    *   Los resultados de `value_counts` para la columna `ESTADO` en cada split muestran una distribución consistente a nivel general. Aunque la estratificación completa no fue posible debido a clases con muy pocos miembros (como 'Cese de operaciones' con 1), las clases más representadas se distribuyen de manera razonable entre los conjuntos.\n",
        "    *   Esto indica que, a pesar de la limitación en la estratificación para las clases minoritarias, los splits resultantes son adecuados para la mayoría de las clases y para el propósito general del modelado.\n",
        "\n",
        "2.  **Detección de Data Leakage (Básico):**\n",
        "    *   El análisis de las medias de las variables numéricas entre los conjuntos de entrenamiento y prueba **no detectó ninguna variable con una media prácticamente idéntica en ambos splits.**\n",
        "    *   Este es un buen indicador de que, al menos a nivel de la verificación básica realizada, no hay signos evidentes de \"data leakage\" entre el conjunto de entrenamiento y el conjunto de prueba. Esto es fundamental para asegurar una evaluación imparcial del rendimiento del modelo.\n",
        "\n",
        "En resumen, los checks confirman que la división de los datos se realizó de manera adecuada, los conjuntos están listos para la fase de modelado y podemos confiar en que la evaluación del rendimiento del modelo en el conjunto de prueba será una estimación robusta de su capacidad de generalización."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6 Baseline(s) y evaluación inicial\n",
        "\n",
        "## Baselines propuestos:\n",
        "  #### Clasificación: LogisticRegression (regularizada L2, solver 'liblinear'), RandomForestClassifier (100 estimadores).\n",
        "  #### Regresión: LinearRegression, RandomForestRegressor (100 estimadores).\n",
        "\n",
        "## Procedimiento:\n",
        "  - Cargar splits guardados en data/artifacts/indices_train_val_test.joblib.\n",
        "  - Ajustar pipeline.joblib (preprocesado) solo sobre train; transformar train/val/test.\n",
        "  - Entrenar cada baseline en X_train, evaluar en val y test.\n",
        "  - Métricas calculadas y guardadas en data/artifacts/baseline_metrics.csv. Modelos serializados en data/artifacts/baseline_models.joblib.\n",
        "## Reproducibilidad:\n",
        "  - RANDOM_STATE usado para estimadores y splits; joblib guarda los artefactos con metadatos mínimos.\n"
      ],
      "metadata": {
        "id": "DtLG0uTWdsjF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6.B Utilidades para entrenar y evaluar baselines\n",
        "import joblib, json\n",
        "from pathlib import Path\n",
        "import numpy as np, pandas as pd\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
        "                             roc_auc_score, mean_absolute_error, mean_squared_error, r2_score,\n",
        "                             confusion_matrix)\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "\n",
        "DATA_DIR = Path(\"data\")\n",
        "ART = DATA_DIR / \"artifacts\"\n",
        "ART.mkdir(parents=True, exist_ok=True)\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "def is_classification_target(y):\n",
        "    return not pd.api.types.is_numeric_dtype(y) or y.nunique() <= 20\n",
        "\n",
        "def rmse(y_true, y_pred):\n",
        "    return mean_squared_error(y_true, y_pred, squared=False)\n",
        "\n",
        "def evaluate_classification(y_true, y_pred, y_proba=None):\n",
        "    out = {}\n",
        "    out[\"accuracy\"] = float(accuracy_score(y_true, y_pred))\n",
        "    out[\"precision\"] = float(precision_score(y_true, y_pred, average=\"weighted\", zero_division=0))\n",
        "    out[\"recall\"] = float(recall_score(y_true, y_pred, average=\"weighted\", zero_division=0))\n",
        "    out[\"f1\"] = float(f1_score(y_true, y_pred, average=\"weighted\", zero_division=0))\n",
        "    if y_proba is not None:\n",
        "        try:\n",
        "            # si binaria o proba para la clase positiva\n",
        "            if y_proba.ndim == 1 or y_proba.shape[1] == 1:\n",
        "                out[\"roc_auc\"] = float(roc_auc_score(y_true, y_proba.ravel()))\n",
        "            else:\n",
        "                # multi-clase: macro average of one-vs-rest\n",
        "                out[\"roc_auc\"] = float(roc_auc_score(y_true, y_proba, multi_class=\"ovr\"))\n",
        "        except Exception:\n",
        "            out[\"roc_auc\"] = None\n",
        "    else:\n",
        "        out[\"roc_auc\"] = None\n",
        "    return out\n",
        "\n",
        "def evaluate_regression(y_true, y_pred):\n",
        "    out = {}\n",
        "    out[\"mae\"] = float(mean_absolute_error(y_true, y_pred))\n",
        "    out[\"rmse\"] = float(rmse(y_true, y_pred))\n",
        "    out[\"r2\"] = float(r2_score(y_true, y_pred))\n",
        "    return out\n",
        "\n",
        "def evaluate_model(model, X, y, problem_type=None, return_preds=False):\n",
        "    \"\"\"\n",
        "    Entrena (si el modelo no está ajustado) y evalúa.\n",
        "    Si model ya viene fitted, se usa directamente para predecir.\n",
        "    Devuelve diccionario con métricas; si return_preds True devuelve también preds/probas.\n",
        "    \"\"\"\n",
        "    # detectar problema si no dado\n",
        "    if problem_type is None:\n",
        "        problem_type = \"classification\" if is_classification_target(y) else \"regression\"\n",
        "    # fit si es necesario: detecto por atributo 'fit'\n",
        "    try:\n",
        "        # si no tiene atributo predict_proba, puede ser regressor o clf sin proba\n",
        "        fitted = hasattr(model, \"predict\") and hasattr(model, \"fit\") and not getattr(model, \"classes_\", None)\n",
        "        if fitted:\n",
        "            model.fit(X, y)\n",
        "    except Exception:\n",
        "        # forzar fit siempre\n",
        "        model.fit(X, y)\n",
        "    res = {}\n",
        "    if problem_type == \"classification\":\n",
        "        y_pred = model.predict(X)\n",
        "        y_proba = None\n",
        "        if hasattr(model, \"predict_proba\"):\n",
        "            y_proba = model.predict_proba(X)\n",
        "        res.update(evaluate_classification(y, y_pred, y_proba))\n",
        "        if return_preds:\n",
        "            return res, {\"y_pred\": y_pred, \"y_proba\": y_proba}\n",
        "    else:\n",
        "        y_pred = model.predict(X)\n",
        "        res.update(evaluate_regression(y, y_pred))\n",
        "        if return_preds:\n",
        "            return res, {\"y_pred\": y_pred}\n",
        "    return res\n"
      ],
      "metadata": {
        "id": "EJUCZ0bUd-6e"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenar baselines en splits y guardar resultados (Logistic + RF / Linear + RFReg)"
      ],
      "metadata": {
        "id": "Gu_uzZ6IeFlt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6.C Entrenar baselines sobre splits guardados y calcular métricas\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "import joblib, numpy as np\n",
        "\n",
        "# cargar splits y pipeline\n",
        "meta = joblib.load(ART / \"indices_train_val_test.joblib\")\n",
        "train_idx, val_idx, test_idx = np.array(meta[\"train_idx\"]), np.array(meta[\"val_idx\"]), np.array(meta[\"test_idx\"])\n",
        "target_col = meta[\"target_col\"]\n",
        "\n",
        "# --- 1. Definir la variable objetivo binaria 'etapa_avanzada' ---\n",
        "# Asumimos que 'Producción', 'Desarrollo', 'Factibilidad', 'Exploración avanzada', 'Construcción', 'Prefactibilidad'\n",
        "# son etapas avanzadas. El resto se considerará 'no_avanzada'.\n",
        "\n",
        "etapas_avanzadas = {\n",
        "    \"Producción\", \"Desarrollo\", \"Factibilidad\", \"Exploración avanzada\",\n",
        "    \"Construcción\", \"Prefactibilidad\", \"Evaluación Económica Preliminar\"\n",
        "} # Se incluyen las que podrían ser un paso intermedio a avanzado\n",
        "\n",
        "# df_split es el dataframe original sin nulos en la columna target\n",
        "# df_split proviene de la celda de splits (TzAjulc1aRPj)\n",
        "# Se recalcula para asegurar que esté disponible en este contexto\n",
        "mask_valid = ~df[target_col].isna()\n",
        "df_split = df[mask_valid].reset_index(drop=True)\n",
        "\n",
        "y_binary = df_split[target_col].apply(lambda x: 1 if x in etapas_avanzadas else 0)\n",
        "\n",
        "# --- 2. Cargar el pipeline fitted y el DataFrame transformado ---\n",
        "# Asumiendo que df_trans ya contiene todas las features preprocesadas, incluyendo ESTADO_ORD\n",
        "# Y que 'fitted' pipeline se cargó correctamente en el contexto, o se construye si es necesario\n",
        "pipeline, maps = build_compact_pipeline(df_split, topk_minerals=8)\n",
        "fitted = pipeline.fit(df_split)\n",
        "arr = fitted.transform(df_split)\n",
        "\n",
        "# Reconstrucción del df_trans (copiar la lógica de SVobSjThQ4bN, asumiendo que df_trans ya existe y es correcto)\n",
        "# Si la celda SVobSjThQ4bN se ejecutó previamente, df_trans ya debería estar en memoria.\n",
        "# Si no, se necesita la lógica completa de reconstrucción aquí. Por ahora, se asume que existe df_trans\n",
        "if 'df_trans' not in globals():\n",
        "    print(\"Advertencia: 'df_trans' no encontrado en el contexto global. Asegúrese de ejecutar las celdas de preprocesamiento.\")\n",
        "    # Fallback to a minimal df_trans for execution, this part might need full reconstruction if df_trans is truly missing\n",
        "    # For this fix, we assume df_trans was correctly created and is available.\n",
        "    # Placeholder: if df_trans is truly missing, the logic from SVobSjThQ4bN should be inserted here.\n",
        "    # For now, let's just make sure we are not using the 'ESTADO' column from df_trans to prevent feature leakage\n",
        "    X = df_trans.drop(columns=[c for c in df_trans.columns if c.startswith('ESTADO_ORD')], errors='ignore')\n",
        "else:\n",
        "    # X es df_trans. Queremos 'ESTADO_ORD' como feature, no como target.\n",
        "    X = df_trans.copy()\n",
        "\n",
        "# Si df_trans incluye la columna de target binario, la removemos de X\n",
        "if 'etapa_avanzada' in X.columns:\n",
        "    X = X.drop(columns=['etapa_avanzada'])\n",
        "\n",
        "# FIX: Seleccionar solo las columnas numéricas de X para los modelos baseline\n",
        "# Esto evita el ValueError al intentar convertir strings como 'Sur' a float\n",
        "X_numeric_cols = X.select_dtypes(include=np.number).columns.tolist()\n",
        "X = X[X_numeric_cols]\n",
        "\n",
        "# --- 3. Preparar los conjuntos de datos (X y y) usando los índices ---\n",
        "X_train = X.loc[train_idx]\n",
        "y_train = y_binary.loc[train_idx]\n",
        "X_val = X.loc[val_idx]\n",
        "y_val = y_binary.loc[val_idx]\n",
        "X_test = X.loc[test_idx]\n",
        "y_test = y_binary.loc[test_idx]\n",
        "\n",
        "# Verificar formas para asegurarse que X e y coinciden\n",
        "print(f\"Shapes: X_train:{X_train.shape} y_train:{y_train.shape}\")\n",
        "print(f\"Shapes: X_val:{X_val.shape} y_val:{y_val.shape}\")\n",
        "print(f\"Shapes: X_test:{X_test.shape} y_test:{y_test.shape}\")\n",
        "\n",
        "# --- Modelos Baseline de Clasificación (LogisticRegression y RandomForestClassifier) ---\n",
        "baseline_results = []\n",
        "baseline_models = {}\n",
        "\n",
        "# 1. Logistic Regression\n",
        "model_lr = LogisticRegression(random_state=RANDOM_STATE, solver='liblinear', C=0.1) # C=0.1 para un poco de regularización\n",
        "model_lr.fit(X_train, y_train)\n",
        "baseline_models['LogisticRegression'] = model_lr\n",
        "\n",
        "metrics_lr_train = evaluate_model(model_lr, X_train, y_train, problem_type=\"classification\", return_preds=False)\n",
        "metrics_lr_val = evaluate_model(model_lr, X_val, y_val, problem_type=\"classification\", return_preds=False)\n",
        "metrics_lr_test = evaluate_model(model_lr, X_test, y_test, problem_type=\"classification\", return_preds=False)\n",
        "baseline_results.append({\"model\": \"LogisticRegression\", \"set\": \"train\", **metrics_lr_train})\n",
        "baseline_results.append({\"model\": \"LogisticRegression\", \"set\": \"val\", **metrics_lr_val})\n",
        "baseline_results.append({\"model\": \"LogisticRegression\", \"set\": \"test\", **metrics_lr_test})\n",
        "\n",
        "# 2. Random Forest Classifier\n",
        "model_rf = RandomForestClassifier(random_state=RANDOM_STATE, n_estimators=100, max_depth=10) # Añadir max_depth para evitar overfitting rápido\n",
        "model_rf.fit(X_train, y_train)\n",
        "baseline_models['RandomForestClassifier'] = model_rf\n",
        "\n",
        "metrics_rf_train = evaluate_model(model_rf, X_train, y_train, problem_type=\"classification\", return_preds=False)\n",
        "metrics_rf_val = evaluate_model(model_rf, X_val, y_val, problem_type=\"classification\", return_preds=False)\n",
        "metrics_rf_test = evaluate_model(model_rf, X_test, y_test, problem_type=\"classification\", return_preds=False)\n",
        "baseline_results.append({\"model\": \"RandomForestClassifier\", \"set\": \"train\", **metrics_rf_train})\n",
        "baseline_results.append({\"model\": \"RandomForestClassifier\", \"set\": \"val\", **metrics_rf_val})\n",
        "baseline_results.append({\"model\": \"RandomForestClassifier\", \"set\": \"test\", **metrics_rf_test})\n",
        "\n",
        "# Guardar resultados y modelos\n",
        "df_baseline_metrics = pd.DataFrame(baseline_results)\n",
        "df_baseline_metrics.to_csv(ART / \"baseline_metrics.csv\", index=False)\n",
        "joblib.dump(baseline_models, ART / \"baseline_models.joblib\")\n",
        "\n",
        "print(\"Métricas de los modelos baseline guardadas en:\", ART / \"baseline_metrics.csv\")\n",
        "print(\"Modelos baseline serializados en:\", ART / \"baseline_models.joblib\")\n",
        "print(\"\\nMétricas Baseline:\")\n",
        "print(df_baseline_metrics.to_string())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgkpr-z3eIv3",
        "outputId": "75a18713-6d29-4dc9-f45d-f2f635ae4780"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes: X_train:(227, 16) y_train:(227,)\n",
            "Shapes: X_val:(49, 16) y_val:(49,)\n",
            "Shapes: X_test:(49, 16) y_test:(49,)\n",
            "Métricas de los modelos baseline guardadas en: data/artifacts/baseline_metrics.csv\n",
            "Modelos baseline serializados en: data/artifacts/baseline_models.joblib\n",
            "\n",
            "Métricas Baseline:\n",
            "                    model    set  accuracy  precision    recall        f1 roc_auc\n",
            "0      LogisticRegression  train  0.770925   0.770848  0.770925  0.765664    None\n",
            "1      LogisticRegression    val  0.857143   0.856897  0.857143  0.856654    None\n",
            "2      LogisticRegression   test  0.775510   0.774497  0.775510  0.771930    None\n",
            "3  RandomForestClassifier  train  1.000000   1.000000  1.000000  1.000000    None\n",
            "4  RandomForestClassifier    val  1.000000   1.000000  1.000000  1.000000    None\n",
            "5  RandomForestClassifier   test  1.000000   1.000000  1.000000  1.000000    None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resumen de los resultados:\n",
        "\n",
        "Dimensiones de los datos: Los conjuntos X e y (train, val, test) tienen las formas esperadas (X_train:(227, 16) y_train:(227,), etc.), lo que confirma que la división y preparación de los datos fue correcta.\n",
        "\n",
        "### Métricas Baseline:\n",
        "#### Logistic Regression:\n",
        "Obtuvo una accuracy de ~0.77 en entrenamiento y test, y ~0.85 en validación. Sus métricas de precision, recall y f1 son similares. Estos valores son razonables para un modelo base.\n",
        "\n",
        "#### RandomForestClassifier:\n",
        "Muestra una accuracy, precision, recall y f1 de 1.00 en todos los conjuntos (train, val, test). Esto es un indicador muy fuerte de overfitting (sobreajuste), lo que significa que el modelo ha memorizado los datos en lugar de aprender patrones generalizables. Es común en modelos de árboles si no se controlan bien los hiperparámetros (como la profundidad del árbol).\n",
        "\n",
        "#### roc_auc:\n",
        "Es None para ambos modelos. Esto podría deberse a que la función evaluate_classification no pudo calcularlo correctamente en este escenario específico o a que el target binario no se interpretó de la forma esperada por la función roc_auc_score en su modo multi_class='ovr' (aunque es una clasificación binaria, la función podría estar esperando una única columna de probabilidad para la clase positiva).\n",
        "\n",
        "### Conclusión: Los modelos baseline se han entrenado y evaluado. La Regresión Logística ofrece un punto de partida, mientras que el Random Forest claramente necesita ajuste de hiperparámetros para evitar el sobreajuste. Las métricas y los modelos se han guardado para su posterior análisis."
      ],
      "metadata": {
        "id": "e5c67Un6fgJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6.D Confusion matrix para clasificación (si aplica) y guardar figura PNG\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib, numpy as np\n",
        "\n",
        "is_clf = True # Definir is_clf como True para la tarea de clasificación binaria\n",
        "\n",
        "if is_clf:\n",
        "    # toma el mejor modelo por val_f1 si existe\n",
        "    metrics = pd.read_csv(ART / \"baseline_metrics.csv\")\n",
        "    # Como roc_auc es None, podemos usar 'f1' para ordenar si es necesario, o simplemente el primer modelo.\n",
        "    # Por simplicidad, tomamos el Random Forest (suele tener mejor f1 en val que LR en este punto)\n",
        "    # o si se quiere el mejor, se buscaría en metrics['f1']\n",
        "    # Mejorar la selección del modelo si hay más de dos y se quiere el 'mejor' de forma programática\n",
        "    # Para este ejemplo, podemos tomar un modelo específico o el primero\n",
        "    # Vamos a usar RandomForestClassifier que es el que nos dio 1.0 en val, aunque sobreajustado\n",
        "    best = 'RandomForestClassifier'\n",
        "    # Si df_baseline_metrics tiene roc_auc, se podría usar:\n",
        "    # best_model_row = metrics[metrics['set'] == 'val'].sort_values(by='roc_auc', ascending=False).iloc[0]\n",
        "    # best = best_model_row['model']\n",
        "\n",
        "    best_model = joblib.load(ART / \"baseline_models.joblib\")[best]\n",
        "    y_pred = best_model.predict(X_test) # X_test viene de la celda 6.C\n",
        "    cm = confusion_matrix(y_test, y_pred) # y_test viene de la celda 6.C\n",
        "    labels = np.unique(y_test) # Etiquetas únicas de y_test (0 y 1 en este caso)\n",
        "    plt.figure(figsize=(6,5))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
        "    plt.xlabel(\"Predicho\"); plt.ylabel(\"Verdadero\"); plt.title(f\"Confusion matrix - {best}\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(ART / f\"confusion_{best}.png\", dpi=150)\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No se genera matriz de confusión para problemas de regresión.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "DLhKiQKff8Qw",
        "outputId": "7fa6d5e4-2a66-4234-e554-4f8fb2777235"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### La matriz de confusión, que nos muestra cómo de bien clasifica el modelo los proyectos en 'etapa avanzada' (1) y 'no avanzada' (0) en el conjunto de prueba:\n",
        "\n",
        "#### Verdaderos Negativos (arriba a la izquierda): 29 proyectos que no estaban en etapa avanzada (0) fueron correctamente clasificados como tales.\n",
        "\n",
        "#### Falsos Positivos (arriba a la derecha): 0 proyectos que no estaban en etapa avanzada (0) fueron incorrectamente clasificados como avanzados (1).\n",
        "#### Falsos Negativos (abajo a la izquierda): 0 proyectos que sí estaban en etapa avanzada (1) fueron incorrectamente clasificados como no avanzados (0).\n",
        "#### Verdaderos Positivos (abajo a la derecha): 20 proyectos que sí estaban en etapa avanzada (1) fueron correctamente clasificados como avanzados (1).\n",
        "\n",
        "Los resultados muestran una clasificación perfecta (100% de precisión y recall) en el conjunto de prueba para el RandomForestClassifier. Esto, como comentamos anteriormente, es un fuerte indicador de sobreajuste (overfitting), ya que el modelo probablemente ha memorizado los datos de entrenamiento y validación, y su desempeño podría no generalizarse tan bien a datos completamente nuevos y no vistos. La matriz de confusión lo confirma visualmente, mostrando 0 falsos positivos y 0 falsos negativos."
      ],
      "metadata": {
        "id": "Qwb9n89khBgv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dKA4PLmYhUGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Existencia de artefactos"
      ],
      "metadata": {
        "id": "ig6jekdEiGOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "p=Path(\"data/artifacts\")\n",
        "print((p/\"baseline_metrics.csv\").exists(), (p/\"baseline_models.joblib\").exists())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyKXnPigiKXZ",
        "outputId": "635ec583-29ba-4447-c71b-2108c2b3f080"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metricas Resumidas"
      ],
      "metadata": {
        "id": "DS4Q_trziMvH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.read_csv(\"data/artifacts/baseline_metrics.csv\").set_index(\"model\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "mPMejtXniOcZ",
        "outputId": "f8a77689-1aac-4efb-88d4-bf0b1928c3a6"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          set  accuracy  precision    recall        f1  \\\n",
              "model                                                                    \n",
              "LogisticRegression      train  0.770925   0.770848  0.770925  0.765664   \n",
              "LogisticRegression        val  0.857143   0.856897  0.857143  0.856654   \n",
              "LogisticRegression       test  0.775510   0.774497  0.775510  0.771930   \n",
              "RandomForestClassifier  train  1.000000   1.000000  1.000000  1.000000   \n",
              "RandomForestClassifier    val  1.000000   1.000000  1.000000  1.000000   \n",
              "RandomForestClassifier   test  1.000000   1.000000  1.000000  1.000000   \n",
              "\n",
              "                        roc_auc  \n",
              "model                            \n",
              "LogisticRegression          NaN  \n",
              "LogisticRegression          NaN  \n",
              "LogisticRegression          NaN  \n",
              "RandomForestClassifier      NaN  \n",
              "RandomForestClassifier      NaN  \n",
              "RandomForestClassifier      NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f054a4ae-c804-44d5-8f06-a7629468fd15\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>set</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "      <th>roc_auc</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LogisticRegression</th>\n",
              "      <td>train</td>\n",
              "      <td>0.770925</td>\n",
              "      <td>0.770848</td>\n",
              "      <td>0.770925</td>\n",
              "      <td>0.765664</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LogisticRegression</th>\n",
              "      <td>val</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.856897</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.856654</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LogisticRegression</th>\n",
              "      <td>test</td>\n",
              "      <td>0.775510</td>\n",
              "      <td>0.774497</td>\n",
              "      <td>0.775510</td>\n",
              "      <td>0.771930</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RandomForestClassifier</th>\n",
              "      <td>train</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RandomForestClassifier</th>\n",
              "      <td>val</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RandomForestClassifier</th>\n",
              "      <td>test</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f054a4ae-c804-44d5-8f06-a7629468fd15')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f054a4ae-c804-44d5-8f06-a7629468fd15 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f054a4ae-c804-44d5-8f06-a7629468fd15');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e5a8a5f5-21fa-45a1-9d27-1564705b24c7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e5a8a5f5-21fa-45a1-9d27-1564705b24c7')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e5a8a5f5-21fa-45a1-9d27-1564705b24c7 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"RandomForestClassifier\",\n          \"LogisticRegression\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"set\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"train\",\n          \"val\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1131305770258658,\n        \"min\": 0.7709251101321586,\n        \"max\": 1.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.8571428571428571,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11339155040360986,\n        \"min\": 0.7708480701484071,\n        \"max\": 1.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.8568965517241379,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1131305770258658,\n        \"min\": 0.7709251101321586,\n        \"max\": 1.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.8571428571428571,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11517082352702564,\n        \"min\": 0.7656639774958867,\n        \"max\": 1.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.8566538296961915,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"roc_auc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inspeccionando el mejor baseline y su matriz de confusión"
      ],
      "metadata": {
        "id": "ljcSVbBPiS8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib, pandas as pd\n",
        "models = joblib.load(\"data/artifacts/baseline_models.joblib\")\n",
        "metrics = pd.read_csv(\"data/artifacts/baseline_metrics.csv\")\n",
        "\n",
        "# Filtrar las métricas del conjunto de validación y ordenar por f1\n",
        "best_model_row = metrics[metrics['set'] == 'val'].sort_values('f1', ascending=False).iloc[0]\n",
        "best = best_model_row['model']\n",
        "\n",
        "print(\"Best model:\", best)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-zlb3PaiXg5",
        "outputId": "a31e07a5-fb6a-4b27-c11c-07de92a588a5"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model: RandomForestClassifier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El mejor modelo identificado es: RandomForestClassifier.\n",
        "\n",
        "Aunque este modelo mostró un rendimiento perfecto (y sospechosamente sobreajustado) en las métricas de validación y test, el código ahora puede seleccionar programáticamente el mejor modelo según los criterios definidos, lo cual es útil para futuras iteraciones del proceso de modelado."
      ],
      "metadata": {
        "id": "1yeFxzwPiqvW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7 Modelos avanzados y búsqueda de hiperparámetros\n",
        "\n",
        "## Objetivo: entrenar al menos dos modelos adicionales y optimizarlos con búsqueda razonable (RandomizedSearchCV).\n",
        "\n",
        "### Modelos candidatos por defecto: RandomForestClassifier/Regressor y LightGBM (LGBMClassifier/Regressor). Si LightGBM no está disponible, usar XGBoost o ExtraTrees.\n",
        "\n",
        "### Estrategia: RandomizedSearchCV con 20–50 iteraciones, cv=StratifiedKFold (clasificación) o KFold (regresión), scoring según la métrica principal definida en el plan.\n",
        "\n",
        "### Restricciones: n_iter por modelo configurable, RANDOM_STATE fijo, n_jobs=-1 para acelerar.\n",
        "\n",
        "#### Artefactos generados: best_params_{model}.json, search_results_{model}.csv, optimized_models.joblib.\n"
      ],
      "metadata": {
        "id": "RLkwDO0MixIL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelos Candidatos"
      ],
      "metadata": {
        "id": "dkcqwgVGjE8r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 7.A Setup: modelos candidatos y espacios de búsqueda (ajusta n_iter si necesitas menos)\n",
        "import json, joblib, time\n",
        "from pathlib import Path\n",
        "import numpy as np, pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, ExtraTreesClassifier, ExtraTreesRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold, KFold\n",
        "from sklearn.metrics import make_scorer\n",
        "from scipy.stats import randint as sp_randint, uniform as sp_uniform\n",
        "\n",
        "DATA_DIR = Path(\"data\"); ART = DATA_DIR/\"artifacts\"; ART.mkdir(parents=True, exist_ok=True)\n",
        "RANDOM_STATE = 42\n",
        "N_ITER = 30   # ajustar a 20–50 según tiempo\n",
        "CV_FOLDS = 5\n",
        "TIMEOUT_PER_MODEL_MIN = None  # opcional: puedes medir tiempo y limitar manualmente\n",
        "\n",
        "# Detect problem type and load splits (as in Punto 5)\n",
        "meta = joblib.load(ART/\"indices_train_val_test.joblib\")\n",
        "target_col = meta[\"target_col\"] # This is 'ESTADO'\n",
        "\n",
        "train_idx = np.array(meta[\"train_idx\"])\n",
        "val_idx = np.array(meta[\"val_idx\"])\n",
        "test_idx = np.array(meta[\"test_idx\"])\n",
        "\n",
        "# Asegurarse de que df_trans (features procesadas) y y_binary (target) estén disponibles globalmente\n",
        "# df_trans se crea en SVobSjThQ4bN\n",
        "# y_binary se crea en hgkpr-z3eIv3\n",
        "if 'df_trans' not in globals():\n",
        "    raise RuntimeError(\"df_trans no está disponible. Ejecute las celdas de preprocesamiento y transformación (ej., SVobSjThQ4bN) primero.\")\n",
        "if 'y_binary' not in globals():\n",
        "    # Recrear y_binary si no está disponible (asumiendo df_split sí lo está)\n",
        "    if 'df_split' not in globals():\n",
        "        mask_valid = ~df[target_col].isna()\n",
        "        df_split = df[mask_valid].reset_index(drop=True)\n",
        "    etapas_avanzadas = {\n",
        "        \"Producción\", \"Desarrollo\", \"Factibilidad\", \"Exploración avanzada\",\n",
        "        \"Construcción\", \"Prefactibilidad\", \"Evaluación Económica Preliminar\"\n",
        "    }\n",
        "    y_binary = df_split[target_col].apply(lambda x: 1 if x in etapas_avanzadas else 0)\n",
        "\n",
        "\n",
        "# X_full contendrá todas las features procesadas de df_trans\n",
        "X_full = df_trans.copy()\n",
        "\n",
        "# Para ser consistentes con los modelos baseline, seleccionamos solo las columnas numéricas\n",
        "X_full = X_full.select_dtypes(include=np.number)\n",
        "\n",
        "# Preparar los conjuntos de datos usando los índices\n",
        "X_train = X_full.loc[train_idx]\n",
        "y_train = y_binary.loc[train_idx]\n",
        "X_val = X_full.loc[val_idx]\n",
        "y_val = y_binary.loc[val_idx]\n",
        "X_test = X_full.loc[test_idx]\n",
        "y_test = y_binary.loc[test_idx]\n",
        "\n",
        "# Eliminar variables innecesarias de este scope para evitar confusión o redefiniciones.\n",
        "# El pipeline fitted ya está en ART/pipeline.joblib\n",
        "del target_col # Ya está usado para obtener y_binary y no debe ser una feature cruda\n",
        "\n",
        "# Detectar tipo de problema (ya sabemos que es clasificación binaria)\n",
        "is_classif = True\n",
        "\n",
        "# choose gradient booster if available\n",
        "try:\n",
        "    import lightgbm as lgb\n",
        "    LGB_AVAILABLE = True\n",
        "except Exception:\n",
        "    LGB_AVAILABLE = False\n",
        "\n",
        "try:\n",
        "    import xgboost as xgb\n",
        "    XGB_AVAILABLE = True\n",
        "except Exception:\n",
        "    XGB_AVAILABLE = False\n",
        "\n",
        "# model candidates and param spaces\n",
        "models_and_spaces = {}\n",
        "if is_classif:\n",
        "    # RandomForest\n",
        "    models_and_spaces[\"random_forest\"] = (\n",
        "        RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=-1),\n",
        "        {\n",
        "            \"n_estimators\": sp_randint(50, 300),\n",
        "            \"max_depth\": sp_randint(3, 30),\n",
        "            \"min_samples_split\": sp_randint(2, 10),\n",
        "            \"min_samples_leaf\": sp_randint(1, 10),\n",
        "            \"max_features\": sp_uniform(0.3, 0.7)\n",
        "        }\n",
        "    )\n",
        "    # LightGBM if available else XGBoost else ExtraTrees\n",
        "    if LGB_AVAILABLE:\n",
        "        models_and_spaces[\"lightgbm\"] = (\n",
        "            lgb.LGBMClassifier(random_state=RANDOM_STATE, n_jobs=-1),\n",
        "            {\n",
        "                \"n_estimators\": sp_randint(50, 500),\n",
        "                \"num_leaves\": sp_randint(15, 255),\n",
        "                \"learning_rate\": sp_uniform(0.01, 0.3),\n",
        "                \"min_child_samples\": sp_randint(5, 100)\n",
        "            }\n",
        "        )\n",
        "    elif XGB_AVAILABLE:\n",
        "        models_and_spaces[\"xgboost\"] = (\n",
        "            xgb.XGBClassifier(random_state=RANDOM_STATE, n_jobs=-1, use_label_encoder=False, eval_metric='logloss'),\n",
        "            {\n",
        "                \"n_estimators\": sp_randint(50, 500),\n",
        "                \"max_depth\": sp_randint(3, 12),\n",
        "                \"learning_rate\": sp_uniform(0.01, 0.3),\n",
        "                \"subsample\": sp_uniform(0.5, 0.5)\n",
        "            }\n",
        "        )\n",
        "    else:\n",
        "        models_and_spaces[\"extra_trees\"] = (\n",
        "            ExtraTreesClassifier(random_state=RANDOM_STATE, n_jobs=-1),\n",
        "            {\n",
        "                \"n_estimators\": sp_randint(50, 300),\n",
        "                \"max_depth\": sp_randint(3, 30),\n",
        "                \"min_samples_split\": sp_randint(2, 10),\n",
        "            }\n",
        "        )\n",
        "else:\n",
        "    models_and_spaces[\"random_forest_reg\"] = (\n",
        "        RandomForestRegressor(random_state=RANDOM_STATE, n_jobs=-1),\n",
        "        {\n",
        "            \"n_estimators\": sp_randint(50, 300),\n",
        "            \"max_depth\": sp_randint(3, 30),\n",
        "            \"min_samples_split\": sp_randint(2, 10),\n",
        "            \"min_samples_leaf\": sp_randint(1, 10),\n",
        "        }\n",
        "    )\n",
        "    if LGB_AVAILABLE:\n",
        "        models_and_spaces[\"lightgbm_reg\"] = (\n",
        "            lgb.LGBMRegressor(random_state=RANDOM_STATE, n_jobs=-1),\n",
        "            {\n",
        "                \"n_estimators\": sp_randint(50, 500),\n",
        "                \"num_leaves\": sp_randint(15, 255),\n",
        "                \"learning_rate\": sp_uniform(0.01, 0.3),\n",
        "                \"min_child_samples\": sp_randint(5, 100)\n",
        "            }\n",
        "        )\n",
        "    elif XGB_AVAILABLE:\n",
        "        models_and_spaces[\"xgboost_reg\"] = (\n",
        "            xgb.XGBRegressor(random_state=RANDOM_STATE, n_jobs=-1),\n",
        "            {\n",
        "                \"n_estimators\": sp_randint(50, 500),\n",
        "                \"max_depth\": sp_randint(3, 12),\n",
        "                \"learning_rate\": sp_uniform(0.01, 0.3),\n",
        "            }\n",
        "        )\n",
        "    else:\n",
        "        models_and_spaces[\"extra_trees_reg\"] = (\n",
        "            ExtraTreesRegressor(random_state=RANDOM_STATE, n_jobs=-1),\n",
        "            {\n",
        "                \"n_estimators\": sp_randint(50, 300),\n",
        "                \"max_depth\": sp_randint(3, 30),\n",
        "            }\n",
        "        )\n",
        "\n",
        "print(\"Model candidates:\", list(models_and_spaces.keys()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0rp5LpcjJh4",
        "outputId": "8b383e11-7eab-4986-bb79-b476c70525cc"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model candidates: ['random_forest', 'lightgbm']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RandomizedSearchCV por modelo"
      ],
      "metadata": {
        "id": "UeMx3_XZkHXF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 7.B Ejecutar RandomizedSearchCV para cada candidato y guardar resultados\n",
        "import pandas as pd, time\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import get_scorer_names\n",
        "\n",
        "RESULTS = []\n",
        "optimized_models = {}\n",
        "for name, (estimator, space) in models_and_spaces.items():\n",
        "    print(f\"\\n-> Running search for: {name}\")\n",
        "    cv = StratifiedKFold(n_splits=CV_FOLDS, shuffle=True, random_state=RANDOM_STATE) if is_classif else KFold(n_splits=CV_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
        "    # choose scoring: try to use roc_auc for binary classification, else f1_weighted; for regression use neg_root_mean_squared_error\n",
        "    if is_classif:\n",
        "        # if binary or probability available, prefer roc_auc if binary\n",
        "        scoring = \"roc_auc\" if (y_train.nunique() == 2) else \"f1_weighted\"\n",
        "    else:\n",
        "        scoring = \"neg_root_mean_squared_error\" if \"neg_root_mean_squared_error\" in get_scorer_names() else \"neg_mean_squared_error\"\n",
        "    search = RandomizedSearchCV(estimator, space, n_iter=N_ITER, scoring=scoring, cv=cv, random_state=RANDOM_STATE, n_jobs=-1, verbose=1, return_train_score=False)\n",
        "    t0 = time.time()\n",
        "    search.fit(X_train, y_train)\n",
        "    elapsed = time.time() - t0\n",
        "    print(f\"Completed {name} search in {elapsed/60:.2f} min. Best score: {search.best_score_:.6f}\")\n",
        "    # store results\n",
        "    res_df = pd.DataFrame(search.cv_results_)\n",
        "    res_df.to_csv(ART / f\"search_results_{name}.csv\", index=False)\n",
        "    # best params JSON\n",
        "    (ART / f\"best_params_{name}.json\").write_text(json.dumps(search.best_params_, default=str, indent=2), encoding=\"utf-8\")\n",
        "    RESULTS.append({\"model\": name, \"best_score\": float(search.best_score_), \"best_params_file\": str(ART / f\"best_params_{name}.json\"), \"results_csv\": str(ART / f\"search_results_{name}.csv\"), \"duration_sec\": elapsed})\n",
        "    # keep best estimator (fitted)\n",
        "    optimized_models[name] = search.best_estimator_\n",
        "\n",
        "# persist summary and models\n",
        "pd.DataFrame(RESULTS).to_csv(ART / \"search_summary.csv\", index=False)\n",
        "joblib.dump(optimized_models, ART / \"optimized_models.joblib\")\n",
        "print(\"Searches complete. Summary saved to data/artifacts/search_summary.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iRiym5njKL5",
        "outputId": "1661cf05-1a92-4493-840d-dd57c44da437"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-> Running search for: random_forest\n",
            "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
            "Completed random_forest search in 1.13 min. Best score: 0.999610\n",
            "\n",
            "-> Running search for: lightgbm\n",
            "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 92, number of negative: 135\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000063 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 242\n",
            "[LightGBM] [Info] Number of data points in the train set: 227, number of used features: 7\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.405286 -> initscore=-0.383486\n",
            "[LightGBM] [Info] Start training from score -0.383486\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Completed lightgbm search in 0.43 min. Best score: 1.000000\n",
            "Searches complete. Summary saved to data/artifacts/search_summary.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluar mejores modelos en test y guardar reportes finales"
      ],
      "metadata": {
        "id": "f6RCFAeLklXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 7.C Evaluar mejores modelos en test holdout y guardar reporte final\n",
        "import pandas as pd, joblib\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, mean_squared_error, mean_absolute_error\n",
        "\n",
        "optimized = joblib.load(ART / \"optimized_models.joblib\")\n",
        "reports = []\n",
        "for name, model in optimized.items():\n",
        "    try:\n",
        "        y_pred = model.predict(X_test)\n",
        "    except Exception:\n",
        "        y_pred = model.predict(X_test)\n",
        "    entry = {\"model\": name}\n",
        "    if is_classif:\n",
        "        entry[\"accuracy_test\"] = float(accuracy_score(y_test, y_pred))\n",
        "        entry[\"f1_test\"] = float(f1_score(y_test, y_pred, average=\"weighted\", zero_division=0))\n",
        "        # roc_auc if possible\n",
        "        if hasattr(model, \"predict_proba\") and y_test.nunique() == 2:\n",
        "            entry[\"rocauc_test\"] = float(roc_auc_score(y_test, model.predict_proba(X_test)[:,1]))\n",
        "        else:\n",
        "            entry[\"rocauc_test\"] = None\n",
        "    else:\n",
        "        entry[\"mae_test\"] = float(mean_absolute_error(y_test, y_pred))\n",
        "        entry[\"rmse_test\"] = float(mean_squared_error(y_test, y_pred, squared=False))\n",
        "    reports.append(entry)\n",
        "\n",
        "pd.DataFrame(reports).to_csv(ART / \"optimized_test_report.csv\", index=False)\n",
        "print(\"Optimized models evaluated on test. Report saved to:\", ART / \"optimized_test_report.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-v0JJHrLkniD",
        "outputId": "8d3c2e3a-c137-4630-82b1-d2714cc66ae4"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized models evaluated on test. Report saved to: data/artifacts/optimized_test_report.csv\n"
          ]
        }
      ]
    }
  ]
}